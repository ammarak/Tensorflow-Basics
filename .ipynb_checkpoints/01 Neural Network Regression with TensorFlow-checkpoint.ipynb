{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27de6828",
   "metadata": {},
   "source": [
    "# Neural Network Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc5913",
   "metadata": {},
   "source": [
    "## What we're going to cover\n",
    "Specifically, we're going to go through doing the following with TensorFlow:\n",
    "\n",
    "* Architecture of a regression model\n",
    "* Input shapes and output shapes\n",
    "    * X: features/data (inputs)\n",
    "    * y: labels (outputs)\n",
    "* Creating custom data to view and fit\n",
    "* Steps in modelling\n",
    "    * Creating a model\n",
    "    * Compiling a model\n",
    "        * Defining a loss function\n",
    "        * Setting up an optimizer\n",
    "        * Creating evaluation metrics\n",
    "    * Fitting a model (getting it to find patterns in our data)\n",
    "* Evaluating a model\n",
    "    * Visualizng the model (\"visualize, visualize, visualize\")\n",
    "    * Looking at training curves\n",
    "    * Compare predictions to ground truth (using our evaluation metrics)\n",
    "* Saving a model (so we can use it later)\n",
    "* Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26583353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5a7c77",
   "metadata": {},
   "source": [
    "## Creating data to view and fit\n",
    "Since we're working on a regression problem (predicting a number) let's create some linear data (a straight line) to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da369a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create features\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad50c156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), ())"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape, y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4649e562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54f06fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Turn X and y into tensors\n",
    "X = tf.constant([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels (using tensors)\n",
    "y = tf.constant([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee270051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2dc9cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a single example of X (model.fit works with numpy array as well)\n",
    "input_shape = X[0].shape \n",
    "\n",
    "# Take a single example of y\n",
    "output_shape = y[0].shape\n",
    "\n",
    "input_shape, output_shape # these are both scalars (no shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17761726",
   "metadata": {},
   "source": [
    "## Steps in modelling with TensorFlow\n",
    "Now we know what data we have as well as the input and output shapes, let's see how we'd build a neural network to model it.\n",
    "\n",
    "In TensorFlow, there are typically 3 fundamental steps to creating and training a model.\n",
    "\n",
    "1. **Creating a model** - piece together the layers of a neural network yourself (using the Functional or Sequential API) or import a previously built model (known as transfer learning).\n",
    "2. **Compiling a model** - defining how a models performance should be measured (loss/metrics) as well as defining how it should improve (optimizer).\n",
    "3. **Fitting a model** - letting the model try to find patterns in the data (how does X get to y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d4eb460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x274969da100>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics= [\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "#model.fit(X, y, epochs=5)  # this will break with TensorFlow 2.7.0+\n",
    "\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "129e1974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
       "array([[-7.],\n",
       "       [-4.],\n",
       "       [-1.],\n",
       "       [ 2.],\n",
       "       [ 5.],\n",
       "       [ 8.],\n",
       "       [11.],\n",
       "       [14.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add one dimension which is inner most\n",
    "tf.expand_dims(X, axis=-1)  # Adds one dimensions at the end(inner most dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d4c3738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8]), TensorShape([8, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One more dimension is added\n",
    "X.shape, tf.expand_dims(X, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "355d3445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In some versions of TensorFlow, we might require float64\n",
    "\n",
    "# Cast to float64\n",
    "X = tf.cast(tf.constant(X), dtype=\"float64\")\n",
    "y = tf.cast(tf.constant(y), dtype=\"float64\")\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1df2198",
   "metadata": {},
   "source": [
    "## Improving a model\n",
    "How do you think you'd improve upon our current model?\n",
    "\n",
    "If you guessed by tweaking some of the things we did above, you'd be correct.\n",
    "\n",
    "To improve our model, we alter almost every part of the 3 steps we went through before.\n",
    "\n",
    "* **Creating a model** - here you might want to add more layers, increase the number of hidden units (also called neurons) within each layer, change the activation functions of each layer.\n",
    "* **Compiling a model** - you might want to choose optimization function or perhaps change the learning rate of the optimization function.\n",
    "* **Fitting a model** - perhaps you could fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from).\n",
    "\n",
    "\n",
    "various options you can use to improve a neural network model There are many different ways to potentially improve a neural network. Some of the most common include: increasing the number of layers (making the network deeper), increasing the number of hidden units (making the network wider) and changing the learning rate. Because these values are all human-changeable, they're referred to as hyperparameters) and the practice of trying to find the best hyperparameters is referred to as hyperparameter tuning.\n",
    "\n",
    "Woah. We just introduced a bunch of possible steps. The important thing to remember is how you alter each of these will depend on the problem you're working on.\n",
    "\n",
    "And the good thing is, over the next few problems, we'll get hands-on with all of them.\n",
    "\n",
    "For now, let's keep it simple, all we'll do is train our model for longer (everything else will stay the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7956306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 11.2219 - mae: 11.2219\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11.0894 - mae: 11.0894\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 10.9569 - mae: 10.9569\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.8244 - mae: 10.8244\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.6919 - mae: 10.6919\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5594 - mae: 10.5594\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.4269 - mae: 10.4269\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.2944 - mae: 10.2944\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.1619 - mae: 10.1619\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.0294 - mae: 10.0294\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.8969 - mae: 9.8969\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.7644 - mae: 9.7644\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.6319 - mae: 9.6319\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.4994 - mae: 9.4994\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.3669 - mae: 9.3669\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.2344 - mae: 9.2344\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.1019 - mae: 9.1019\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9694 - mae: 8.9694\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.8369 - mae: 8.8369\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.7044 - mae: 8.7044\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.5719 - mae: 8.5719\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.4394 - mae: 8.4394\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.3069 - mae: 8.3069\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.1744 - mae: 8.1744\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.0419 - mae: 8.0419\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9094 - mae: 7.9094\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7769 - mae: 7.7769\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.6444 - mae: 7.6444\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5119 - mae: 7.5119\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3794 - mae: 7.3794\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2750 - mae: 7.2750\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.2694 - mae: 7.2694\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2638 - mae: 7.2638\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2581 - mae: 7.2581\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2412 - mae: 7.2412\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1962 - mae: 7.1962\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1737 - mae: 7.1737\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.1062 - mae: 7.1062\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.8869 - mae: 6.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27497caed30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Improving the model by increasing the epochs\n",
    "\n",
    "# First Create the Sequence and then add layers\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics= [\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "713ed01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.739855]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Prediction using Model\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53674a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights :  [[1.7008739]]\n",
      "Biases :  [0.8249995]\n"
     ]
    }
   ],
   "source": [
    "# See the biases and Weights of the layer 1(the only layer)\n",
    "print(\"Weights : \",model.layers[0].get_weights()[0])\n",
    "print(\"Biases : \", model.layers[0].get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d1d28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.3315462"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict it with weights and biases\n",
    "\n",
    "1.0217066 * 17.0 + 9.962534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c99360f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 10.5736 - mae: 10.5736\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 10.5691 - mae: 10.5691\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.5646 - mae: 10.5646\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5601 - mae: 10.5601\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 10.5556 - mae: 10.5556\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5511 - mae: 10.5511\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5466 - mae: 10.5466\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.5421 - mae: 10.5421\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5376 - mae: 10.5376\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5331 - mae: 10.5331\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5286 - mae: 10.5286\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.5241 - mae: 10.5241\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5196 - mae: 10.5196\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5151 - mae: 10.5151\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5106 - mae: 10.5106\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.5061 - mae: 10.5061\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5016 - mae: 10.5016\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.4971 - mae: 10.4971\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.4926 - mae: 10.4926\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.4881 - mae: 10.4881\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.4836 - mae: 10.4836\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.4791 - mae: 10.4791\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.4746 - mae: 10.4746\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.4701 - mae: 10.4701\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.4656 - mae: 10.4656\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.4611 - mae: 10.4611\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.4566 - mae: 10.4566\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.4521 - mae: 10.4521\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.4476 - mae: 10.4476\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10.4431 - mae: 10.4431\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.4386 - mae: 10.4386\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.4341 - mae: 10.4341\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.4296 - mae: 10.4296\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.4251 - mae: 10.4251\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.4206 - mae: 10.4206\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.4161 - mae: 10.4161\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.4116 - mae: 10.4116\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.4071 - mae: 10.4071\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.4026 - mae: 10.4026\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.3981 - mae: 10.3981\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.3936 - mae: 10.3936\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.3891 - mae: 10.3891\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.3846 - mae: 10.3846\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.3801 - mae: 10.3801\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.3756 - mae: 10.3756\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.3711 - mae: 10.3711\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.3666 - mae: 10.3666\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.3621 - mae: 10.3621\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.3576 - mae: 10.3576\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.3531 - mae: 10.3531\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.3486 - mae: 10.3486\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.3441 - mae: 10.3441\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.3396 - mae: 10.3396\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.3351 - mae: 10.3351\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.3306 - mae: 10.3306\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.3261 - mae: 10.3261\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10.3216 - mae: 10.3216\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.3171 - mae: 10.3171\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.3126 - mae: 10.3126\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.3081 - mae: 10.3081\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.3036 - mae: 10.3036\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.2991 - mae: 10.2991\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10.2946 - mae: 10.2946\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.2901 - mae: 10.2901\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.2856 - mae: 10.2856\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.2811 - mae: 10.2811\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.2766 - mae: 10.2766\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.2721 - mae: 10.2721\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.2676 - mae: 10.2676\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.2631 - mae: 10.2631\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.2586 - mae: 10.2586\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.2541 - mae: 10.2541\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.2496 - mae: 10.2496\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.2451 - mae: 10.2451\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.2406 - mae: 10.2406\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.2361 - mae: 10.2361\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.2316 - mae: 10.2316\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.2271 - mae: 10.2271\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.2226 - mae: 10.2226\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.2181 - mae: 10.2181\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.2136 - mae: 10.2136\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.2091 - mae: 10.2091\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 10.2046 - mae: 10.2046\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.2001 - mae: 10.2001\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.1956 - mae: 10.1956\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.1911 - mae: 10.1911\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 10.1866 - mae: 10.1866\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.1821 - mae: 10.1821\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 10.1776 - mae: 10.1776\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.1731 - mae: 10.1731\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.1686 - mae: 10.1686\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.1641 - mae: 10.1641\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.1596 - mae: 10.1596\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.1551 - mae: 10.1551\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.1506 - mae: 10.1506\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.1461 - mae: 10.1461\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.1416 - mae: 10.1416\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.1371 - mae: 10.1371\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.1326 - mae: 10.1326\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.1281 - mae: 10.1281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27498f583d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Improving the model by changing the Optimizer\n",
    "\n",
    "# First Create the Sequence and then add layers\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.Adam(),\n",
    "             metrics= [\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b40c0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 14.0407 - mae: 14.0407\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 13.4800 - mae: 13.4800\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.9217 - mae: 12.9217\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 12.3612 - mae: 12.3612\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.7937 - mae: 11.7937\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 11.2106 - mae: 11.2106\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.6209 - mae: 10.6209\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.0058 - mae: 10.0058\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.3625 - mae: 9.3625\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.6887 - mae: 8.6887\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.9730 - mae: 7.9730\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.2130 - mae: 7.2130\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3984 - mae: 6.3984\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5215 - mae: 5.5215\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5762 - mae: 4.5762\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0920 - mae: 4.0920\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.0292 - mae: 4.0292\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.9887 - mae: 3.9887\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.9591 - mae: 3.9591\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8951 - mae: 3.8951\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9391 - mae: 3.9391\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8718 - mae: 3.8718\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9498 - mae: 3.9498\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8853 - mae: 3.8853\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9245 - mae: 3.9245\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8929 - mae: 3.8929\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8991 - mae: 3.8991\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9005 - mae: 3.9005\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8734 - mae: 3.8734\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9084 - mae: 3.9084\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8507 - mae: 3.8507\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9226 - mae: 3.9226\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8550 - mae: 3.8550\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9021 - mae: 3.9021\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8628 - mae: 3.8628\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8763 - mae: 3.8763\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8707 - mae: 3.8707\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8504 - mae: 3.8504\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8787 - mae: 3.8787\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8298 - mae: 3.8298\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8932 - mae: 3.8932\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8259 - mae: 3.8259\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8783 - mae: 3.8783\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8339 - mae: 3.8339\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8523 - mae: 3.8523\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8420 - mae: 3.8420\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.8262 - mae: 3.8262\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8517 - mae: 3.8517\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8055 - mae: 3.8055\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8648 - mae: 3.8648\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7979 - mae: 3.7979\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8533 - mae: 3.8533\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8061 - mae: 3.8061\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8270 - mae: 3.8270\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8144 - mae: 3.8144\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8006 - mae: 3.8006\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8264 - mae: 3.8264\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7796 - mae: 3.7796\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8376 - mae: 3.8376\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7710 - mae: 3.7710\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8270 - mae: 3.8270\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7794 - mae: 3.7794\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8004 - mae: 3.8004\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7879 - mae: 3.7879\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7737 - mae: 3.7737\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8027 - mae: 3.8027\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7524 - mae: 3.7524\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8114 - mae: 3.8114\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7451 - mae: 3.7451\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7994 - mae: 3.7994\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7537 - mae: 3.7537\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7726 - mae: 3.7726\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7624 - mae: 3.7624\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7474 - mae: 3.7474\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7774 - mae: 3.7774\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7238 - mae: 3.7238\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7863 - mae: 3.7863\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7203 - mae: 3.7203\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7705 - mae: 3.7705\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7290 - mae: 3.7290\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7433 - mae: 3.7433\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7379 - mae: 3.7379\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7196 - mae: 3.7196\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7531 - mae: 3.7531\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6939 - mae: 3.6939\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7622 - mae: 3.7622\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6964 - mae: 3.6964\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7403 - mae: 3.7403\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7054 - mae: 3.7054\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7128 - mae: 3.7128\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7145 - mae: 3.7145\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6903 - mae: 3.6903\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7299 - mae: 3.7299\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6645 - mae: 3.6645\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7364 - mae: 3.7364\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6735 - mae: 3.6735\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7087 - mae: 3.7087\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6827 - mae: 3.6827\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6808 - mae: 3.6808\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6927 - mae: 3.6927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27499001a60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Improving the model by adding hidden layer/activation layer\n",
    "\n",
    "# First Create the Sequence and then add layers\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics= [\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af1308ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.61212677e-01, -8.03425163e-02, -2.09173420e-04,\n",
       "        -7.81371519e-02, -1.21386983e-01, -1.08752167e-04,\n",
       "         1.30758554e-01,  3.14059779e-02, -3.83749418e-02,\n",
       "         3.68519872e-01,  2.54075438e-01, -6.25823885e-02,\n",
       "         3.85899425e-01, -2.23256171e-01,  1.37326298e-02,\n",
       "        -1.71171024e-01,  2.10863933e-01, -7.16423430e-03,\n",
       "        -2.23240796e-02,  1.72199726e-01, -1.54933613e-03,\n",
       "        -1.59216017e-01, -2.43976310e-01,  6.73253089e-06,\n",
       "        -6.69135712e-04, -9.43104997e-02,  4.57427576e-02,\n",
       "         3.63957673e-01,  1.54667422e-01,  1.25781521e-01,\n",
       "         1.20955341e-01, -1.71127498e-01, -4.70626615e-02,\n",
       "         2.53377169e-01, -6.01241216e-02,  1.42727420e-01,\n",
       "        -2.50803381e-01,  3.06323737e-01, -1.20638870e-05,\n",
       "        -2.20094889e-01, -1.74710359e-02, -1.85169950e-01,\n",
       "        -1.03852682e-01,  2.35911787e-01,  6.37538135e-02,\n",
       "         3.34798060e-02,  9.71878693e-02,  2.07609817e-01,\n",
       "        -2.68734366e-01, -1.80952892e-01,  1.67067558e-01,\n",
       "        -7.05109909e-04,  3.20647180e-01, -1.14763275e-01,\n",
       "        -3.65665928e-02, -5.06131090e-02, -7.20736161e-02,\n",
       "        -1.35453731e-01,  2.72772908e-01, -7.58085996e-02,\n",
       "         1.60614446e-01,  1.61716387e-01, -1.49389297e-01,\n",
       "         4.23441008e-02,  1.13057949e-01, -8.25211406e-02,\n",
       "        -1.54304534e-01,  1.21952832e-01, -6.03836142e-02,\n",
       "        -6.02739155e-02,  1.02813102e-01,  1.45508811e-01,\n",
       "        -5.54981045e-02,  1.31081250e-02, -1.73006207e-01,\n",
       "        -1.15338480e-04, -5.23894615e-02,  1.14224195e-01,\n",
       "         1.79523602e-04,  4.35436994e-01,  4.42324668e-01,\n",
       "         7.95018449e-02,  2.15097971e-05, -2.39401802e-01,\n",
       "         4.53258753e-01, -4.45246994e-02, -1.79235592e-01,\n",
       "        -6.02274723e-02,  1.12371579e-01,  2.83266958e-02,\n",
       "        -2.41844915e-04, -5.06896935e-02, -1.21148497e-01,\n",
       "        -3.61885913e-02, -1.16161101e-01, -4.12043631e-02,\n",
       "         1.27224252e-04,  1.45421892e-01, -2.18643650e-01,\n",
       "         1.26069188e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fc0bbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07622829,  0.0032176 , -0.00424582,  0.04201979,  0.01810577,\n",
       "       -0.00856633,  0.03656131, -0.02078604, -0.04085802,  0.0976724 ,\n",
       "        0.08701775, -0.02339187,  0.10938033,  0.02717014, -0.00625416,\n",
       "        0.04282103,  0.05572517, -0.00291859,  0.00370028,  0.00757574,\n",
       "       -0.01163263, -0.02500253,  0.01120459, -0.00143632, -0.00510395,\n",
       "        0.04130499, -0.02171025,  0.08784226,  0.06589963, -0.02808041,\n",
       "       -0.01505954, -0.01256951,  0.0162304 ,  0.0643148 ,  0.03727233,\n",
       "       -0.00778267,  0.0265603 ,  0.07277479, -0.00651241,  0.03477424,\n",
       "       -0.00389925,  0.05062972,  0.0248084 ,  0.09374256, -0.03021521,\n",
       "       -0.04523477, -0.02482447,  0.08994121,  0.03804594, -0.02942741,\n",
       "        0.01553281, -0.01652098,  0.08884637,  0.03844718, -0.01866312,\n",
       "       -0.01799813, -0.01223571,  0.02320055,  0.03855195,  0.01709758,\n",
       "        0.04282609,  0.00420174, -0.03033335, -0.0449276 , -0.0334111 ,\n",
       "       -0.03282231, -0.01506338,  0.01999294,  0.02384784, -0.00319861,\n",
       "        0.01876054,  0.03545694, -0.03751257, -0.01972291, -0.00623989,\n",
       "       -0.00582675, -0.00560276, -0.0006914 , -0.00469296,  0.11293586,\n",
       "        0.11636286, -0.01812153, -0.00068219,  0.02006252,  0.12747781,\n",
       "        0.00201699,  0.04561399,  0.03495765,  0.01560262, -0.02778828,\n",
       "       -0.00479915,  0.0069518 ,  0.00436373, -0.02086932,  0.02102779,\n",
       "        0.01357067, -0.00968487,  0.05161076,  0.0045844 ,  0.05357318],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d7ceab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.727648]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seems like our model is overfitting the data too much\n",
    "\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a18a9e4",
   "metadata": {},
   "source": [
    "### Common ways  to improve a deep model\n",
    "\n",
    "* **Adding layers**\n",
    "* **Increasing the number of hidden units**\n",
    "* **Change the activation function**\n",
    "* **Change the optimizer**\n",
    "* **Change the Learning rate**\n",
    "* **Fitting for more data**\n",
    "* **Fitting for longer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e9d5e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 13.3252 - mae: 13.3252\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.8093 - mae: 12.8093\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.2911 - mae: 12.2911\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.7680 - mae: 11.7680\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 11.2372 - mae: 11.2372\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.6959 - mae: 10.6959\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.1416 - mae: 10.1416\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.5711 - mae: 9.5711\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9817 - mae: 8.9817\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.3704 - mae: 8.3704\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.7339 - mae: 7.7339\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2082 - mae: 7.2082\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1865 - mae: 7.1865\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1647 - mae: 7.1647\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1430 - mae: 7.1430\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1211 - mae: 7.1211\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0992 - mae: 7.0992\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0772 - mae: 7.0772\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0552 - mae: 7.0552\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0109 - mae: 7.0109\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9886 - mae: 6.9886\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9663 - mae: 6.9663\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9439 - mae: 6.9439\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9213 - mae: 6.9213\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8987 - mae: 6.8987\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8760 - mae: 6.8760\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8532 - mae: 6.8532\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8303 - mae: 6.8303\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8073 - mae: 6.8073\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7841 - mae: 6.7841\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.7609 - mae: 6.7609\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7375 - mae: 6.7375\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7140 - mae: 6.7140\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6904 - mae: 6.6904\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6666 - mae: 6.6666\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6427 - mae: 6.6427\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6187 - mae: 6.6187\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5945 - mae: 6.5945\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5702 - mae: 6.5702\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.5535 - mae: 6.5535\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.5402 - mae: 6.5402\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.5160 - mae: 6.5160\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.4917 - mae: 6.4917\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4671 - mae: 6.4671\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.4424 - mae: 6.4424\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.4176 - mae: 6.4176\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3925 - mae: 6.3925\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3673 - mae: 6.3673\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3418 - mae: 6.3418\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3162 - mae: 6.3162\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.2904 - mae: 6.2904\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.2644 - mae: 6.2644\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.2382 - mae: 6.2382\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.2118 - mae: 6.2118\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.1851 - mae: 6.1851\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.1583 - mae: 6.1583\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.1312 - mae: 6.1312\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.1039 - mae: 6.1039\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.0763 - mae: 6.0763\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0594 - mae: 6.0594\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0453 - mae: 6.0453\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.0177 - mae: 6.0177\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.9898 - mae: 5.9898\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.9616 - mae: 5.9616\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.9332 - mae: 5.9332\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.9045 - mae: 5.9045\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.8755 - mae: 5.8755\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.8463 - mae: 5.8463\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.8167 - mae: 5.8167\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.7869 - mae: 5.7869\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.7568 - mae: 5.7568\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7265 - mae: 5.7265\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.6958 - mae: 5.6958\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.6648 - mae: 5.6648\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6335 - mae: 5.6335\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6018 - mae: 5.6018\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.5922 - mae: 5.5922\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.5772 - mae: 5.5772\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6981 - mae: 5.6981\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4992 - mae: 5.4992\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4665 - mae: 5.4665\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4334 - mae: 5.4334\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.3999 - mae: 5.3999\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3661 - mae: 5.3661\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.3319 - mae: 5.3319\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.2973 - mae: 5.2973\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2624 - mae: 5.2624\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2346 - mae: 5.2346\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.3011 - mae: 5.3011\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.3440 - mae: 5.3440\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1487 - mae: 5.1487\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1123 - mae: 5.1123\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0755 - mae: 5.0755\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0383 - mae: 5.0383\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0006 - mae: 5.0006\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.9625 - mae: 4.9625\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.9240 - mae: 4.9240\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8850 - mae: 4.8850\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.8578 - mae: 4.8578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x274990cbc10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Improving the model by adding just the hidden layer without activation function\n",
    "# Reducing number of hidden units\n",
    "\n",
    "# First Create the Sequence and then add layers\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation=None))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics= [\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "726acf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.75227]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e5d0ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.8549 - mae: 11.8549\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 11.7827 - mae: 11.7827\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 11.7104 - mae: 11.7104\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 11.6381 - mae: 11.6381\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 11.5658 - mae: 11.5658\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 11.4934 - mae: 11.4934\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 11.4209 - mae: 11.4209\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11.3483 - mae: 11.3483\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 11.2757 - mae: 11.2757\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 11.2030 - mae: 11.2030\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 11.1302 - mae: 11.1302\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 11.0573 - mae: 11.0573\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 10.9843 - mae: 10.9843\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 10.9112 - mae: 10.9112\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.8380 - mae: 10.8380\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.7646 - mae: 10.7646\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 10.6912 - mae: 10.6912\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 10.6175 - mae: 10.6175\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 10.5438 - mae: 10.5438\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.4699 - mae: 10.4699\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.3958 - mae: 10.3958\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.3216 - mae: 10.3216\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.2472 - mae: 10.2472\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10.1726 - mae: 10.1726\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.0978 - mae: 10.0978\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.0228 - mae: 10.0228\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9476 - mae: 9.9476\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.8722 - mae: 9.8722\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7966 - mae: 9.7966\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.7207 - mae: 9.7207\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.6446 - mae: 9.6446\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.5682 - mae: 9.5682\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.4916 - mae: 9.4916\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.4147 - mae: 9.4147\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.3375 - mae: 9.3375\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.2601 - mae: 9.2601\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.1823 - mae: 9.1823\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.1042 - mae: 9.1042\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.0259 - mae: 9.0259\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.9472 - mae: 8.9472\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.8682 - mae: 8.8682\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7888 - mae: 8.7888\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.7091 - mae: 8.7091\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.6291 - mae: 8.6291\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.5487 - mae: 8.5487\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.4679 - mae: 8.4679\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.3868 - mae: 8.3868\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3053 - mae: 8.3053\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.2234 - mae: 8.2234\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.1411 - mae: 8.1411\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.0584 - mae: 8.0584\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.9753 - mae: 7.9753\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.8918 - mae: 7.8918\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.8078 - mae: 7.8078\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7235 - mae: 7.7235\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.6387 - mae: 7.6387\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5534 - mae: 7.5534\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.4678 - mae: 7.4678\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3816 - mae: 7.3816\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2950 - mae: 7.2950\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2080 - mae: 7.2080\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1205 - mae: 7.1205\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.0325 - mae: 7.0325\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9440 - mae: 6.9440\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9321 - mae: 6.9321\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9216 - mae: 6.9216\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.9113 - mae: 6.9113\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9013 - mae: 6.9013\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.8914 - mae: 6.8914\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8816 - mae: 6.8816\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8720 - mae: 6.8720\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8625 - mae: 6.8625\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8531 - mae: 6.8531\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8438 - mae: 6.8438\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.8346 - mae: 6.8346\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8255 - mae: 6.8255\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8279 - mae: 6.8279\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.8345 - mae: 6.8345\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.8349 - mae: 6.8349\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8296 - mae: 6.8296\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.8193 - mae: 6.8193\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8043 - mae: 6.8043\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.7853 - mae: 6.7853\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.7639 - mae: 6.7639\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7572 - mae: 6.7572\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7502 - mae: 6.7502\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.7432 - mae: 6.7432\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.7359 - mae: 6.7359\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.7286 - mae: 6.7286\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7211 - mae: 6.7211\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7134 - mae: 6.7134\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.7057 - mae: 6.7057\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6979 - mae: 6.6979\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.6900 - mae: 6.6900\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6820 - mae: 6.6820\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6739 - mae: 6.6739\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6657 - mae: 6.6657\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.6574 - mae: 6.6574\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6491 - mae: 6.6491\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.6407 - mae: 6.6407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2749a152f70>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Improving the model by changing the optimization\n",
    "\n",
    "# First Create the Sequence and then add layers\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation=None))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.Adam(),\n",
    "             metrics= [\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0429681b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.317047]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efcc5ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 734ms/step - loss: 14.2190 - mae: 14.2190\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.5222 - mae: 13.5222\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.8277 - mae: 12.8277\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 12.1351 - mae: 12.1351\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.4431 - mae: 11.4431\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.7496 - mae: 10.7496\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.0519 - mae: 10.0519\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.3466 - mae: 9.3466\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.6305 - mae: 8.6305\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.9001 - mae: 7.9001\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1520 - mae: 7.1520\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.7056 - mae: 6.7056\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8974 - mae: 6.8974\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.1929 - mae: 7.1929\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.4650 - mae: 7.4650\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.5928 - mae: 7.5928\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.5230 - mae: 7.5230\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3026 - mae: 7.3026\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9837 - mae: 6.9837\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7448 - mae: 6.7448\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.4880 - mae: 6.4880\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.2173 - mae: 6.2173\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.0636 - mae: 6.0636\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.0210 - mae: 6.0210\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0911 - mae: 6.0911\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.1629 - mae: 6.1629\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.1349 - mae: 6.1349\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.0196 - mae: 6.0196\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.8261 - mae: 5.8261\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.5859 - mae: 5.5859\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4871 - mae: 5.4871\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3856 - mae: 5.3856\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.2977 - mae: 5.2977\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2779 - mae: 5.2779\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.2172 - mae: 5.2172\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.1187 - mae: 5.1187\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.9860 - mae: 4.9860\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.8269 - mae: 4.8269\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.7377 - mae: 4.7377\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.6423 - mae: 4.6423\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5406 - mae: 4.5406\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4325 - mae: 4.4325\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.3178 - mae: 4.3178\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1964 - mae: 4.1964\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.0680 - mae: 4.0680\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9325 - mae: 3.9325\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7897 - mae: 3.7897\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6392 - mae: 3.6392\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4809 - mae: 3.4809\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.3144 - mae: 3.3144\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.1728 - mae: 3.1728\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.9969 - mae: 2.9969\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.7997 - mae: 2.7997\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.6203 - mae: 2.6203\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4299 - mae: 2.4299\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2284 - mae: 2.2284\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0155 - mae: 2.0155\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7988 - mae: 1.7988\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5428 - mae: 1.5428\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4096 - mae: 1.4096\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2272 - mae: 1.2272\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8590 - mae: 0.8590\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6155 - mae: 0.6155\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3959 - mae: 0.3959\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0218 - mae: 0.0218\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4711 - mae: 0.4711\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6543 - mae: 0.6543\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5963 - mae: 0.5963\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7228 - mae: 0.7228\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8335 - mae: 0.8335\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6917 - mae: 0.6917\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6132 - mae: 0.6132\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6307 - mae: 0.6307\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4528 - mae: 0.4528\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3386 - mae: 0.3386\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2970 - mae: 0.2970\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0411 - mae: 0.0411\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1313 - mae: 0.1313\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2561 - mae: 0.2561\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2130 - mae: 0.2130\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2437 - mae: 0.2437\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1688 - mae: 0.1688\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1495 - mae: 0.1495\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0528 - mae: 0.0528\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1045 - mae: 0.1045\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1800 - mae: 0.1800\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1774 - mae: 0.1774\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2042 - mae: 0.2042\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1517 - mae: 0.1517\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1144 - mae: 0.1144\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0645 - mae: 0.0645\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1452 - mae: 0.1452\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1613 - mae: 0.1613\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1584 - mae: 0.1584\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0845 - mae: 0.0845\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2478 - mae: 0.2478\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1990 - mae: 0.1990\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1410 - mae: 0.1410\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1533 - mae: 0.1533\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1460 - mae: 0.1460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2749a22fa60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Improving the model by changing the Learning Rate\n",
    "\n",
    "# First Create the Sequence and then add layers\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation=None))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.Adam(lr=0.01),\n",
    "             metrics= [\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "636a40e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.675222]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6dcde0",
   "metadata": {},
   "source": [
    "## Evaluating a Model\n",
    "\n",
    "A typical workflow you'll go through when building neural networks is:\n",
    "\n",
    "**Build a model -> evaluate it -> build (tweak) a model -> evaulate it -> build (tweak) a model -> evaluate it...**\n",
    "\n",
    "The tweaking comes from maybe not building a model from scratch but adjusting an existing one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff3fda7",
   "metadata": {},
   "source": [
    "**Note:** Hyperparameter are the things that we can tweak during model fitting, while parameters are the things while fiiting the model, which the model learns itself, which we cannot tweak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1432604c",
   "metadata": {},
   "source": [
    "### Visualise\n",
    "\n",
    "When it comes to evaluate, its better to visualize\n",
    "\n",
    "* **The data** - what data are you working with? What does it look like?\n",
    "* **The model itself** - what does the architecture look like? What are the different shapes?\n",
    "* **The training of a model** - how does a model perform while it learns?\n",
    "* **The predictions of a model** - how do the predictions of a model line up against the ground truth (the original labels)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af46c4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make bigger Datasets\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d7572b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset (adhering to the same pattern as before)\n",
    "y = np.arange(-90, 110, 4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4eca9a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = X + 10\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfb4398",
   "metadata": {},
   "source": [
    "## Split data into training/test set\n",
    "\n",
    "One of the other most common and important steps in a machine learning project is creating a training and test set (and when required, a validation set).\n",
    "\n",
    "Each set serves a specific purpose:\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available (like the course materials you study during the semester).\n",
    "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the total data available (like the practice exam you take before the final exam).\n",
    "* **Test set** - the model gets evaluated on this data to test what it has learned, it's typically 10-15% of the total data available (like the final exam you take at the end of the semester).\n",
    "\n",
    "\n",
    "For now, we'll just use a training and test set, this means we'll have a dataset for our model to learn on as well as be evaluated on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4807883a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many samples we have\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4928e6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train = X[:40] # first 40 examples (80% of data)\n",
    "y_train = y[:40]\n",
    "\n",
    "X_test = X[40:] # last 10 examples (20% of data)\n",
    "y_test = y[40:]\n",
    "\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203081a1",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "Now we've got our training and test data, it's a good idea to visualize it.\n",
    "\n",
    "Let's plot it with some nice colours to differentiate what's what."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aeac3d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 7))\n",
    "\n",
    "plt.scatter(X_train, y_train, c='b', label='Training data')\n",
    "\n",
    "plt.scatter(X_test, y_test, c='g', label='Testing Data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a20272e",
   "metadata": {},
   "source": [
    "With this graph in mind, what we'll be trying to do is build a model which learns the pattern in the blue dots (X_train) to draw the green dots (X_test).\n",
    "\n",
    "Time to build a model. We'll make the exact same one from before (the one we trained for longer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5efa144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics = ['mae'])\n",
    "\n",
    "# Fit the model\n",
    "#model.fit(tf.expand_dims(X_train, -1), y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90652679",
   "metadata": {},
   "source": [
    "## Visualizing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52e395ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb6a935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by defining the input_shape argument\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape =  [1])  # Define the input shape to our model\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d34b2bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This will work after specifying the input shape\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d0615",
   "metadata": {},
   "source": [
    "Dense layer means fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e3aebf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(X_train, -1)[0].shape  # the input shape should be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f164f0",
   "metadata": {},
   "source": [
    "* **Total params** - total number of parameters in the model.\n",
    "* **Trainable parameters** - these are the parameters (patterns) the model can update as it trains.\n",
    "* **Non-trainable parameters** - these parameters aren't updated during training (this is typical when you bring in the already learned patterns from other models during transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d5da772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2749a13e460>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to training data\n",
    "model.fit(X_train, y_train, epochs = 100, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dd8cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc941acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model = model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeefcc6",
   "metadata": {},
   "source": [
    "## Naming the layers and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cec12319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by defining the input_shape argument\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape =  [1], name = \"input_layer\"),  # Define the input shape to our model\n",
    "    tf.keras.layers.Dense(1, name = \"output_layer\")\n",
    "], name = \"model 1\")\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "492609d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model 1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42860668",
   "metadata": {},
   "source": [
    "## Visualizing the Predictions\n",
    "\n",
    "* To visualize predictions, it's always a good idea to plot them against the ground truth labels.\n",
    "\n",
    "* Often you'll see this in the form of y_test vs. y_pred (ground truth vs. predictions).\n",
    "\n",
    "* First, we'll make some predictions on the test data (X_test), remember the model has never seen the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65c03867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27496737940>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# First Create the Sequence and then add layers\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation=None))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.Adam(lr=0.01),\n",
    "             metrics= [\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ff0172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002749603B4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "y_preds = model.predict(tf.expand_dims(X_test, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a83585b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 69.05404 ],\n",
       "       [ 72.99317 ],\n",
       "       [ 76.93228 ],\n",
       "       [ 80.87139 ],\n",
       "       [ 84.810524],\n",
       "       [ 88.74965 ],\n",
       "       [ 92.68877 ],\n",
       "       [ 96.62789 ],\n",
       "       [100.56702 ],\n",
       "       [104.50614 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e81f238d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5f859ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train, \n",
    "                     train_labels=y_train, \n",
    "                     test_data=X_test, \n",
    "                     test_labels=y_test, \n",
    "                     predictions=y_preds):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
    "  # Plot the predictions in red (predictions were made on the test data)\n",
    "  plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
    "  # Show the legend\n",
    "  plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78ca7711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(train_data=X_train,\n",
    "                 train_labels=y_train,\n",
    "                 test_data=X_test,\n",
    "                 test_labels=y_test,\n",
    "                 predictions=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96616a64",
   "metadata": {},
   "source": [
    "## Evaluating predictions\n",
    "Alongisde visualizations, evaulation metrics are your alternative best option for evaluating your model.\n",
    "\n",
    "Depending on the problem you're working on, different models have different evaluation metrics.\n",
    "\n",
    "Two of the main metrics used for regression problems are:\n",
    "\n",
    "* Mean absolute error (MAE) - the mean difference between each of the predictions.\n",
    "* Mean squared error (MSE) - the squared mean difference between of the predictions (use if larger errors are more detrimental than smaller errors).\n",
    "The lower each of these values, the better.\n",
    "\n",
    "You can also use model.evaluate() which will return the loss of the model as well as any metrics setup during the compile step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fea79a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 312ms/step - loss: 1.2199 - mae: 1.2199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2199127674102783, 1.2199127674102783]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6329009",
   "metadata": {},
   "source": [
    "In our case, since we used MAE for the loss function as well as MAE for the metrics, model.evaulate() returns them both.\n",
    "\n",
    "TensorFlow also has built in functions for MSE and MAE.\n",
    "\n",
    "For many evaluation functions, the premise is the same: compare predictions to the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aac55b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([18.945961, 15.605463, 13.040631, 11.251444, 10.237895, 10.      ,\n",
       "       10.537753, 11.851156, 13.94021 , 16.804913], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean absolute error\n",
    "mae = tf.metrics.mean_absolute_error(y_true=y_test,\n",
    "                                    y_pred=y_preds)\n",
    "\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0198a",
   "metadata": {},
   "source": [
    "Huh? That's strange, MAE should be a single output.\n",
    "\n",
    "Instead, we get 10 values.\n",
    "\n",
    "This is because our y_test and y_preds tensors are different shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd60b842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 70  74  78  82  86  90  94  98 102 106], shape=(10,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the albel tensor value\n",
    "print(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af1daef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 69.05404 ],\n",
       "       [ 72.99317 ],\n",
       "       [ 76.93228 ],\n",
       "       [ 80.87139 ],\n",
       "       [ 84.810524],\n",
       "       [ 88.74965 ],\n",
       "       [ 92.68877 ],\n",
       "       [ 96.62789 ],\n",
       "       [100.56702 ],\n",
       "       [104.50614 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the predictions tensor values (notice the extra square brackets)\n",
    "print(type(y_preds))\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3bafa64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10]), (10, 1))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the tensor shapes\n",
    "y_test.shape, y_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f44c4e3",
   "metadata": {},
   "source": [
    "Remember how we discussed dealing with different input and output shapes is one the most common issues you'll come across, this is one of those times.\n",
    "\n",
    "But not to worry.\n",
    "\n",
    "We can fix it using squeeze(), it'll remove the the 1 dimension from our y_preds tensor, making it the same shape as y_test.\n",
    "\n",
    "🔑 **Note**: If you're comparing two tensors, it's important to make sure they're the right shape(s) (you won't always have to manipulate the shapes, but always be on the look out, many errors are the result of mismatched tensors, especially mismatched input and output shapes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7c73d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape before squeeze()\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "70a7a27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shhape after squeeze()\n",
    "y_preds.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09498d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>,\n",
       " array([ 69.05404 ,  72.99317 ,  76.93228 ,  80.87139 ,  84.810524,\n",
       "         88.74965 ,  92.68877 ,  96.62789 , 100.56702 , 104.50614 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What do they look like?\n",
    "y_test, y_preds.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ded147",
   "metadata": {},
   "source": [
    "Okay, now we know how to make our y_test and y_preds tenors the same shape, let's use our evaluation metrics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b88ea73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.2199128>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcuate the MAE\n",
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, \n",
    "                                     y_pred=y_preds.squeeze()) # use squeeze() to make same shape\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e737d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the same as tf.metrics.mean_absolute_error()\n",
    "tf.reduce_mean(tf.abs(y_test-y_preds.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74c9882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntions\n",
    "\n",
    "def mae(y_test, y_pred):\n",
    "  \"\"\"\n",
    "  Calculuates mean absolute error between y_test and y_preds.\n",
    "  \"\"\"\n",
    "  return tf.metrics.mean_absolute_error(y_test,\n",
    "                                        y_pred)\n",
    "  \n",
    "def mse(y_test, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates mean squared error between y_test and y_preds.\n",
    "  \"\"\"\n",
    "  return tf.metrics.mean_squared_error(y_test,\n",
    "                                       y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783a66eb",
   "metadata": {},
   "source": [
    "## Running experiments to improve a model\n",
    "\n",
    "After seeing the evaluation metrics and the predictions your model makes, it's likely you'll want to improve it.\n",
    "\n",
    "Again, there are many different ways you can do this, but 3 of the main ones are:\n",
    "\n",
    "1. **Get more data** - get more examples for your model to train on (more opportunities to learn patterns).\n",
    "2. **Make your model larger (use a more complex model)** - this might come in the form of more layers or more hidden units in each layer.\n",
    "3. **Train for longer** - give your model more of a chance to find the patterns in the data.\n",
    "\n",
    "Since we created our dataset, we could easily make more data but this isn't always the case when you're working with real-world datasets.\n",
    "\n",
    "So let's take a look at how we can improve our model using 2 and 3.\n",
    "\n",
    "To do so, we'll build 3 models and compare their results:\n",
    "\n",
    "1. model_1 - same as original model, 1 layer, trained for 100 epochs.\n",
    "2. model_2 - 2 layers, trained for 100 epochs.\n",
    "3. model_3 - 2 layers, trained for 500 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e70f2",
   "metadata": {},
   "source": [
    "**Build model_1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "491e4b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 15.9024 - mae: 15.9024\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 11.2837 - mae: 11.2837\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 11.1075 - mae: 11.1075\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2990 - mae: 9.2990\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.1677 - mae: 10.1677\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 9.4303 - mae: 9.4303\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.5704 - mae: 8.5704\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 9.0442 - mae: 9.0442\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.7517 - mae: 18.7517\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.1142 - mae: 10.1142\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.3980 - mae: 8.3980\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 10.6639 - mae: 10.6639\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.7977 - mae: 9.7977\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 16.0103 - mae: 16.0103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.4068 - mae: 11.4068\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5393 - mae: 8.5393\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 13.6348 - mae: 13.6348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.4629 - mae: 11.4629\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 17.9148 - mae: 17.9148\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 15.0494 - mae: 15.0494\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 11.0216 - mae: 11.0216\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 8.1558 - mae: 8.1558\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.5138 - mae: 9.5138\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.6617 - mae: 7.6617\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.1859 - mae: 13.1859\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 16.4211 - mae: 16.4211\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1660 - mae: 13.1660\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.2559 - mae: 14.2559\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.0670 - mae: 10.0670\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.3409 - mae: 16.3409\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 23.6444 - mae: 23.6444\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.6215 - mae: 7.6215\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.3221 - mae: 9.3221\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.7313 - mae: 13.7313\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.1276 - mae: 11.1276\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 13.3222 - mae: 13.3222\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.4763 - mae: 9.4763\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.1381 - mae: 10.1381\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1793 - mae: 10.1793\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9137 - mae: 10.9137\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9063 - mae: 7.9063\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0914 - mae: 10.0914\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7006 - mae: 8.7006\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.2046 - mae: 12.2046\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7970 - mae: 13.7970\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4687 - mae: 8.4687\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1330 - mae: 9.1330\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6190 - mae: 10.6190\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.7503 - mae: 7.7503\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5407 - mae: 9.5407\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1584 - mae: 9.1584\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.3630 - mae: 16.3630\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1299 - mae: 14.1299\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.1247 - mae: 21.1247\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3961 - mae: 16.3961\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9806 - mae: 9.9806\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.9606 - mae: 9.9606\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.2209 - mae: 9.2209\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.4239 - mae: 8.4239\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4869 - mae: 9.4869\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4354 - mae: 11.4354\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.6887 - mae: 11.6887\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.9675 - mae: 16.9675\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.4599 - mae: 12.4599\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0184 - mae: 13.0184\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.0600 - mae: 8.0600\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.1888 - mae: 10.1888\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.3633 - mae: 12.3633\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0516 - mae: 9.0516\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0378 - mae: 10.0378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.0516 - mae: 10.0516\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.6151 - mae: 12.6151\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.3819 - mae: 10.3819\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7229 - mae: 9.7229\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.2252 - mae: 11.2252\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.3642 - mae: 8.3642\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1274 - mae: 9.1274\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.5039 - mae: 19.5039\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.8945 - mae: 14.8945\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0034 - mae: 9.0034\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0206 - mae: 13.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9299 - mae: 7.9299\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6872 - mae: 7.6872\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.0328 - mae: 10.0328\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2433 - mae: 9.2433\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.0209 - mae: 12.0209\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6389 - mae: 10.6389\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.2667 - mae: 7.2667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.7786 - mae: 12.7786\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.7175 - mae: 7.7175\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1263 - mae: 7.1263\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.6190 - mae: 12.6190\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.0912 - mae: 10.0912\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3558 - mae: 9.3558\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6834 - mae: 12.6834\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.6762 - mae: 8.6762\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.4693 - mae: 9.4693\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.7067 - mae: 8.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2749b423c70>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Repicate the orginal model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer = tf.keras.optimizers.SGD(),\n",
    "               metrics = ['mae'])\n",
    "\n",
    "# Fit the model\n",
    "model_1.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8dc1999d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make prediction and plor prediction\n",
    "y_preds_1 = model_1.predict(X_test)\n",
    "plot_predictions(predictions = y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c5d9837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18.745327, 353.57336)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 metrics\n",
    "mae_1 = mae(y_test, y_preds_1.squeeze()).numpy()\n",
    "mse_1 = mse(y_test, y_preds_1.squeeze()).numpy()\n",
    "\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b161605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d874e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8713099]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.weights[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5612170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2924998], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.weights[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d94e3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8713099]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f914f23b",
   "metadata": {},
   "source": [
    "**Build model_2**\n",
    "\n",
    "This time we'll add an extra dense layer (so now our model will have 2 layers) whilst keeping everything else the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "60699b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2749b54b100>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Replicate model_1 and add an extra layer\n",
    "model_2 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1) # add a second layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=['mae'])\n",
    "\n",
    "# Fit the model\n",
    "model_2.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100, verbose=0) # set verbose t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2c65a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "92da722b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2818765 , -0.05931674,  0.23022771, -0.22770092, -0.18401685,\n",
       "         0.4626208 ,  0.55024564,  0.4963325 , -0.33856735, -0.18170239]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.layers[0].weights[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee19cdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28547657],\n",
       "       [-0.06006661],\n",
       "       [ 0.23325726],\n",
       "       [-0.23063993],\n",
       "       [-0.18625344],\n",
       "       [ 0.46855634],\n",
       "       [ 0.557299  ],\n",
       "       [ 0.50264543],\n",
       "       [-0.34286737],\n",
       "       [-0.18396898]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.layers[1].weights[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b3c97ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAGbCAYAAAAV7J4cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuC0lEQVR4nO3df3RU9Z3/8dcbUBBhUTH1BzQJtlgEjEGy2AIqKbVorT/Pqti4pWsVcXVVerRUObXYc7JHXWtd21Wauh51T1ZxtX6tK7oWKqWt7dJQ0xB+KCoJUjmYxYpQREh4f/+YSUjCTDIhc+/M3Pt8nJOTzGd+fZiZwIvPvfd1zd0FAACA4A3I9QQAAADiguAFAAAQEoIXAABASAheAAAAISF4AQAAhGRQrieQqWOPPdZLS0tzPQ0AAIBerV69+v/cvaj7eMEEr9LSUtXV1eV6GgAAAL0ys+ZU42xqBAAACAnBCwAAICQELwAAgJAUzD5eqezbt09btmzRnj17cj0VSBoyZIhGjx6tww47LNdTAQAgLxV08NqyZYuGDx+u0tJSmVmupxNr7q7t27dry5YtGjNmTK6nAwBAXiroTY179uzRyJEjCV15wMw0cuRIVh8BAOhBQQcvSYSuPMJ7AQBAzwo+eAEAABQKglc/bN++XeXl5SovL9fxxx+vUaNGdVzeu3dvj/etq6vTTTfd1OtzTJ06NVvT7WLGjBm9FtI+8MAD2r17dyDPDwBAHBX0zvW5NnLkSNXX10uSFi1apGHDhunWW2/tuL61tVWDBqV+iSsqKlRRUdHrc7z22mtZmeuheOCBB3TVVVdp6NChOZsDAABREqsVr9paqbRUGjAg8b22NvvP8Y1vfEPf+ta3VFlZqQULFmjVqlWaOnWqJk2apKlTp+qNN96QJK1YsUJf/epXJSVC29VXX60ZM2bopJNO0oMPPtjxeMOGDeu4/YwZM/R3f/d3GjdunKqqquTukqSlS5dq3Lhxmj59um666aaOx+3s448/1uzZs1VWVqYrrrhCH3/8ccd1119/vSoqKjRhwgR973vfkyQ9+OCDeu+991RZWanKysq0twMAAJmLzYpXba00d67UvuWsuTlxWZKqqrL7XG+++aaWLVumgQMH6qOPPtLKlSs1aNAgLVu2THfccYeeffbZg+6zYcMGvfrqq9q5c6c+97nP6frrrz+oD+v111/X2rVrdeKJJ2ratGn67W9/q4qKCl133XVauXKlxowZoyuvvDLlnB5++GENHTpUDQ0Namho0Omnn95xXXV1tY455hi1tbVp5syZamho0E033aT7779fr776qo499ti0tysrK8viKwcAQLTFZsVr4cIDoavd7t2J8Wy77LLLNHDgQEnSjh07dNlll2nixImaP3++1q5dm/I+559/vgYPHqxjjz1Wn/rUp7Rt27aDbjNlyhSNHj1aAwYMUHl5uZqamrRhwwaddNJJHd1Z6YLXypUrddVVV0mSysrKugSmp59+WqeffromTZqktWvXat26dSkfI9PbAQCA1GITvDZv7tt4fxx55JEdP3/3u99VZWWlGhsb9cILL6TtuRo8eHDHzwMHDlRra2tGt2nf3JiJVHUPmzZt0n333afly5eroaFB559/fso5Zno7AADyUhj7G2UgNsGruLhv49myY8cOjRo1SpL02GOPZf3xx40bp3feeUdNTU2SpCVLlqS83VlnnaXa5IessbFRDQ0NkqSPPvpIRx55pEaMGKFt27bppZde6rjP8OHDtXPnzl5vBwBAXmvf36i5WXI/sL9RDsJXbIJXdbXU/eC8oUMT40H69re/rdtvv13Tpk1TW1tb1h//iCOO0EMPPaRzzz1X06dP13HHHacRI0YcdLvrr79eu3btUllZme69915NmTJFknTaaadp0qRJmjBhgq6++mpNmzat4z5z587Veeedp8rKyh5vBwBAXgtzf6NeWF82VeVSRUWFd++dWr9+vU455ZSMH6O2NvEab96cWOmqrs7+jvW5sGvXLg0bNkzurhtuuEFjx47V/PnzczKXvr4nAAAEbsCAxEpXd2bS/v2BPKWZrXb3g3qjYrPiJSVCVlNT4jVuaopG6JKkn/70pyovL9eECRO0Y8cOXXfddbmeEgAA+SNX+xulEJs6iSibP39+zla4AADIe9XVXTulpHD2N0ohViteAAAghqqqpJoaqaQksXmxpCRxOQebvgheAACgcGVaE5En+xuxqREAABSmME9LkyWseAEAgMKURzURmSJ49cP27dtVXl6u8vJyHX/88Ro1alTH5b179/Z6/xUrVui1117ruLx48WI98cQTWZ9n5xNyp1NfX6+lS5dm/bkBAAhMH05LU7umVqUPlGrAXQNU+kCpatfkprmeTY39MHLkSNXX10uSFi1apGHDhunWW2/N+P4rVqzQsGHDNHXqVEnSvHnzgphmRurr61VXV6evfOUrOZsDAAB9Ulyc2LyYaryT2jW1mvvCXO3el1gda97RrLkvJDZJVp0a7ibJWK14hZF2V69erbPPPluTJ0/WrFmztHXrVknSgw8+qPHjx6usrEyzZ89WU1OTFi9erB/+8IcqLy/Xr3/9ay1atEj33XefJGnGjBlasGCBpkyZopNPPlm//vWvJUm7d+/W5ZdfrrKyMl1xxRU644wz1L1YVpJefvlljRs3TtOnT9fPfvazjvFVq1Zp6tSpmjRpkqZOnao33nhDe/fu1Z133qklS5aovLxcS5YsSXk7AADySoanpVm4fGFH6Gq3e99uLVwe/ibJ2Kx4hZF23V3/9E//pOeff15FRUVasmSJFi5cqEcffVR33323Nm3apMGDB+vDDz/UUUcdpXnz5nVZJVu+fHmXx2ttbdWqVau0dOlS3XXXXVq2bJkeeughHX300WpoaFBjY6PKy8sPmseePXt07bXX6pe//KU++9nP6oorrui4bty4cVq5cqUGDRqkZcuW6Y477tCzzz6r73//+6qrq9OPf/xjSYlzM6a6HQAAeaN9B/peTkuzeUfqTZLpxoMUm+DVU9rNVvD65JNP1NjYqHPOOUeS1NbWphNOOEGSVFZWpqqqKl188cW6+OKLM3q8Sy+9VJI0efLkjpNg/+Y3v9HNN98sSZo4caLKysoOut+GDRs0ZswYjR07VpJ01VVXqaamRlLipN1z5szRxo0bZWbat29fyufO9HYAAORUVVWvRzAWjyhW846DN0kWjwi/uT42mxrDSLvurgkTJqi+vl719fVas2aNXnnlFUnSiy++qBtuuEGrV6/W5MmT1dra2uvjDR48WJI0cODAjttnem5NM0s5/t3vfleVlZVqbGzUCy+8oD179vTrdgAABCLTfq4MVM+s1tDDum6SHHrYUFXPpLk+MOlSbTbT7uDBg9XS0qLf/e53kqR9+/Zp7dq12r9/v959911VVlbq3nvv1Ycffqhdu3Zp+PDh2rlzZ5+eY/r06Xr66aclSevWrdOaNWsOus24ceO0adMmvf3225KkJ598suO6HTt2aNSoUZKkxx57rGO8+1zS3Q4AgMC193M1NydObt3ez5UifGWy/3bVqVWquaBGJSNKZDKVjChRzQU1oe9YL8UoeIWRdgcMGKBnnnlGCxYs0Gmnnaby8nK99tpramtr01VXXaVTTz1VkyZN0vz583XUUUfpggsu0HPPPdexc30m/vEf/1EtLS0qKyvTPffco7KyMo0YMaLLbYYMGaKamhqdf/75mj59ukpKSjqu+/a3v63bb79d06ZNU1tbW8d4ZWWl1q1b17FzfbrbAQAQuAz7udr3327e0SyXd+y/nS58Nd3SpP3f26+mW5pyErokyTLddJVrFRUV3v3ovfXr1+uUU07J+DFq19Rq4fKF2rxjs4pHFKt6ZnXOXvhD1dbWpn379mnIkCF6++23NXPmTL355ps6/PDDcz01SX1/TwAAOMiAAYmVru7MEqf8SSp9oDTlvlslI0rUdEtTgBPsnZmtdveK7uOx2bleSqTdQgta3e3evVuVlZXat2+f3F0PP/xw3oQuAACyIsN+rnw6WjFTWdnUaGaPmtn7ZtbYaewYM/uFmW1Mfj+603W3m9lbZvaGmc3KxhziYvjw4aqrq9Of/vQnNTQ06Lzzzsv1lAAAyK4M+7nC2H8727K1j9djks7tNvYdScvdfayk5cnLMrPxkmZLmpC8z0NmNjBL8wAAAIWuqkqqqZFKShKbF0tKEpe71Ubk09GKmcpK8HL3lZI+6DZ8kaTHkz8/LuniTuNPufsn7r5J0luSpmRjHgAAICKqqqSmpsQ+XU1NKbu68uloxUwFeVTjce6+VZKS3z+VHB8l6d1Ot9uSHDuImc01szozq2tpaQlwqgAAIHB96ObK9DR/+XK0YqZysXN9qmbPlIdWunuNpBopcVRjkJMCAAABau/maq+JaO/mkg5azcqnk1pnW5ArXtvM7ARJSn5/Pzm+RdKnO91utKT3ApxHoAYOHKjy8nJNnDhRl112mXZ37x3pg2984xt65plnJEnXXHON1q1bl/a2K1as0GuvvdZxefHixXriiScO+bkBAAhUht1cUn6d1DrbggxeP5c0J/nzHEnPdxqfbWaDzWyMpLGSVgU4j0AdccQRqq+vV2Njow4//HAtXry4y/WHWj76yCOPaPz48Wmv7x685s2bp69//euH9FwAAARuc5qKhxTjhVgTkals1Uk8Kel3kj5nZlvM7JuS7pZ0jpltlHRO8rLcfa2kpyWtk/SypBvcPZxq9Cye9ymVM888U2+99ZZWrFihyspKfe1rX9Opp56qtrY23Xbbbfrbv/1blZWV6Sc/+YmkxHkXb7zxRo0fP17nn3++3n///Y7HmjFjhtoLY19++WWdfvrpOu200zRz5kw1NTVp8eLF+uEPf9jRer9o0SLdd999kqT6+np9/vOfV1lZmS655BL95S9/6XjMBQsWaMqUKTr55JM72vLXrl2rKVOmqLy8XGVlZdq4cWNWXxcAALp3cPU0Xog1EZnKyj5e7n5lmqtmprl9taRwj/Xsw7blQ9Ha2qqXXnpJ556baNVYtWqVGhsbNWbMGNXU1GjEiBH6wx/+oE8++UTTpk3Tl7/8Zb3++ut64403tGbNGm3btk3jx4/X1Vdf3eVxW1padO2112rlypUaM2aMPvjgAx1zzDGaN2+ehg0bpltvvVWStHz58o77fP3rX9ePfvQjnX322brzzjt111136YEHHuiY56pVq7R06VLdddddWrZsmRYvXqybb75ZVVVV2rt3L6cIAgBkX3V113+HpZTdXFKiJqLzPl5S/tdEZCo252rsy7blvvj4449VXl6uiooKFRcX65vf/KYkacqUKRozZowk6ZVXXtETTzyh8vJynXHGGdq+fbs2btyolStX6sorr9TAgQN14okn6otf/OJBj//73/9eZ511VsdjHXPMMT3OZ8eOHfrwww919tlnS5LmzJmjlStXdlx/6aWXSpImT56spqYmSdIXvvAF/fM//7PuueceNTc364gjjujXawIAwEEy7OaSCrMmIlPxOWVQH7Yt90X7Pl7dHXnkkR0/u7t+9KMfadasriX9S5culVmqgzwPcPdeb9MXgwcPlpQ4KKC1tVWS9LWvfU1nnHGGXnzxRc2aNUuPPPJIyhAIAEB/1JZJC2+RNu+QikdI1WVSuigVhdP8pRKfFa8+bFvOtlmzZunhhx/Wvn37JElvvvmm/vrXv+qss87SU089pba2Nm3dulWvvvrqQff9whe+oF/96lfatGmTJOmDDxI9tcOHD9fOnTsPuv2IESN09NFHd+y/9R//8R8dq1/pvPPOOzrppJN000036cILL1RDQ0O//rwAgJjJYB/q9oqI5h3NcnlHRUS6fq6oik/wyvC8T0G45pprNH78eJ1++umaOHGirrvuOrW2tuqSSy7R2LFjdeqpp+r6669PGZCKiopUU1OjSy+9VKeddpquuOIKSdIFF1yg5557rmPn+s4ef/xx3XbbbSorK1N9fb3uvPPOHue3ZMkSTZw4UeXl5dqwYQNHRwIAMte+D3Vzs+R+YB/qbuEryhURfWHuhdFLWlFR4e1H+bVbv369TjnllMwfpLY2sU/X5s2Jla7q6qzsWI8D+vyeAAAKW2lpImx1V1KSONVP0oC7BshT9KWbTPu/tz+4+eWIma1294ru4/HZx0tKhCyCFgAA2ZPhPtTFI4rVvOPggBaFioi+iM+mRgAAkH0Z7kNdPbNaQw/rustPVCoi+qLgg1ehbCqNA94LAIihDPehjnJFRF8U9KbGIUOGaPv27Ro5cmRWKxfQd+6u7du3a8iQIbmeCgAgTFVV+s27v1XpvTU68S9teu/ogWr69hxNT9PPFbeg1V1BB6/Ro0dry5YtamlpyfVUoEQQHj16dK6nAQAIUe2aWs3d/7h239x+1pM2Dd3/uGrWTIt9yEqloI9qBAAAAcqgDaD0gdKUO82XjChR0y1NIU00/3BUIwAAyFyG5zjevCP1UY3pxuOu4HeuBwAAAcjwHMfp6iDiVhORKYIXAAA4WIb9XNRE9A3BCwAAHCzDfi5qIvqGfbwAAMDBqqvVes3VGrRnb8dQ65DDNSjFOY6picgcK14AAOAgtWXStRe4mkZI+yU1jUhcri3L9cwKG3USAADgINRE9E+6OglWvAAAiJPaWqm0VBowIPG9tjblzaiJCAbBCwCAuGjv5mpultwPdHOlCF/URASD4AUAQFxk2M0lURMRFIIXAABxkWE3l0RNRFCokwAAIC6KixObF1ONp0BNRPax4gUAQEz8Zt5X9NfDuo799bDEOMJB8AIAICauGrJU116gbt1ciXGEg02NAADExOYdm9VcJj3ZrQTVqIgIDSteAABEQQb9XFRE5B7BCwCAQpdhPxcVEblH8AIAoNBl2M9FRUTuca5GAAAK3YABiZWu7syk/fvDnw84VyMAAFG16/hj+jSO3CF4AQBQ4O74olL2c93xxdzMB+kRvAAAKHA/HvtByn6uH4/9INdTQzcELwAA8lmGNRFPlklj5ksDFyW+P1lGTUQ+CjR4mdnnzKy+09dHZnaLmS0ysz93GudcBQAAdEdNROSEdlSjmQ2U9GdJZ0j6B0m73P2+TO/PUY0AgNgpLU19UuuSEqmpqctQ7ZpaLVy+UJt3bFbxiGJVz6ymJiKH0h3VGOYpg2ZKetvdm80sxKcFAKAw+eZmpfoXM9V41alVBK0CEOY+XrMlPdnp8o1m1mBmj5rZ0anuYGZzzazOzOpaWlrCmSUAAHniz0cN7NM48l8owcvMDpd0oaT/Sg49LOkzksolbZX0g1T3c/cad69w94qioqIwpgoAQN5YUNmWsiZiQWVbbiaEfgtrxes8SX90922S5O7b3L3N3fdL+qmkKSHNAwCAgvHbM0tS1kT89sySXE8NhyisfbyuVKfNjGZ2grtvTV68RFJjSPMAAKBgVM+s1tzdc/Vk2YHzMA49bKhqOFqxYAW+4mVmQyWdI+lnnYbvNbM1ZtYgqVLS/KDnAQBA3sigm0vipNZRxEmyAQAIU22tWq+5WoP27O0Yah1yuAY98qhURaCKCk6SDQBAHth1281dQpckDdqzV7tuuzlHM0KYCF4AAIRo6NbtfRpHtBC8AAAI0eYRfRtHtBC8AAAI0f1fHZmym+v+r47MzYQQKoIXAAAhOmPBv+rGiw/r0s1148WH6YwF/5rrqSEEYZ6rEQCA2Ks6tUr6rjRjKie0jiPqJAAAyJLaWmnhQmnzZqm4WKqupiEirtLVSbDiBQBAFtTWSnPnSruTJfPNzYnLEuELB7CPFwAAWbBw4YHQ1W737sQ40I7gBQBAFmze3LdxxBPBCwCALCgu7ts44ongBQBAFlRXS0OHdh0bOjQxDrQjeAEAkAVVVVJNjVRSIpklvtfUsGM9uiJ4AQDQg9paqbRUGjAg8b22Nv1tq6qkpiZp//7Ed0IXuqNOAgCANKiIQLax4gUAQBpURCDbCF4AAKRBRQSyjeAFAEAaVEQg2wheAACkQUUEso3gBQBAGlREINsIXgCAWMq0JoKKCGQTdRIAgNihJgK5wooXACB2qIlArhC8AACxQ00EcoXgBQCIHWoikCsELwBA7FATgVwheAEAYoeaCOQKwQsAECnURCCfUScBAIgMaiKQ71jxAgBEBjURyHcELwBAZFATgXxH8AIARAY1Ech3BC8AQGRQE4F8F3jwMrMmM1tjZvVmVpccO8bMfmFmG5Pfjw56HgCA6KMmAvkurBWvSncvd/eK5OXvSFru7mMlLU9eBgAgpUwrIiRqIpDfcrWp8SJJjyd/flzSxTmaBwAgz7VXRDQ3S+4HKiJ6Cl9AvgojeLmkV8xstZkl21R0nLtvlaTk90+FMA8AQAGiIgJREkaB6jR3f8/MPiXpF2a2IdM7JoPaXEkq5pAUAIglKiIQJYGveLn7e8nv70t6TtIUSdvM7ARJSn5/P819a9y9wt0rioqKgp4qACAPURGBKAk0eJnZkWY2vP1nSV+W1Cjp55LmJG82R9LzQc4DAFC4qIhAlAS94nWcpN+Y2Z8krZL0oru/LOluSeeY2UZJ5yQvAwBiJpOjFamIQJSYu+d6DhmpqKjwurq6XE8DAJAl3U9oLSVWsghViAIzW92pRqsDzfUAgJzgaEXEEcELAJATHK2IOCJ4AQBygqMVEUcELwBATnC0IuKI4AUAyAmOVkQcEbwAAFmX6UmtOaE14iaMUwYBAGKke01E+0mtJYIVwIoXACCrqIkA0iN4AQCyipoIID2CFwAgq6iJANIjeAEAsoqaCCA9ghcAIKuoiQDSI3gBADKSaUWERE0EkA51EgCAXlERAWQHK14AgF5REQFkB8ELANArKiKA7CB4AQB6RUUEkB0ELwBAr6iIALKD4AUA6BUVEUB2ELwAIOYyrYmgIgLoP+okACDGqIkAwsWKFwDEGDURQLgIXgAQY9REAOEieAFAjFETAYSL4AUAMUZNBBAughcAxBg1EUC4CF4AEFHURAD5hzoJAIggaiKA/MSKFwBEEDURQH4ieAFABFETAeQnghcARBA1EUB+IngBQARREwHkJ4IXAEQQNRFAfiJ4AUABybQiQqImAshHgQYvM/u0mb1qZuvNbK2Z3ZwcX2Rmfzaz+uTXV4KcBwBEQXtFRHOz5H6gIqKn8AUgv5i7B/fgZidIOsHd/2hmwyWtlnSxpMsl7XL3+zJ9rIqKCq+rqwtmogBQAEpLE2Gru5KSxIoWgPxhZqvdvaL7eKAFqu6+VdLW5M87zWy9pFFBPicARBUVEUDhC20fLzMrlTRJ0v8mh240swYze9TMjk5zn7lmVmdmdS0tLWFNFQDyEhURQOELJXiZ2TBJz0q6xd0/kvSwpM9IKldiRewHqe7n7jXuXuHuFUVFRWFMFQDyFhURQOELPHiZ2WFKhK5ad/+ZJLn7Nndvc/f9kn4qaUrQ8wCAQkdFBFD4gj6q0ST9u6T17n5/p/ETOt3sEkmNQc4DAPJdpjURVEQAhS3QneslTZP095LWmFl9cuwOSVeaWbkkl9Qk6bqA5wEAeau9JqL9pNbtNRESwQqImkDrJLKJOgkAUUVNBBA96eokaK4HgByjJgKID4IXAOQYNRFAfBC8ACDHqIkA4oPgBQAByuRoRWoigPgI+qhGAIitvhytWFVF0ALigBUvAAjIwoUHQle73bsT4wDiieAFAAHhaEUA3RG8ACAgHK0IoDuCFwAEhKMVAXRH8AKAgHC0IoDuCF4A0EeZntBa4qTWALqiTgIA+oATWgPoD1a8AKAPqIgA0B8ELwDoAyoiAPQHwQsA+oCKCAD9QfACgD6gIgJAfxC8AKAPqIgA0B8ELwBIyrQmgooIAIeKOgkAEDURAMLBihcAiJoIAOEgeAGAqIkAEA6CFwCImggA4SB4AYCoiQAQDoIXAIiaCADhIHgBiDxqIgDkC+okAEQaNREA8gkrXgAijZoIAPmE4AUg0qiJAJBPCF4AIo2aCAD5hOAFINKoiQCQTwheACKNmggA+YTgBaAgZVoRIVETASB/UCcBoOBQEQGgULHiBaDgUBEBoFDlLHiZ2blm9oaZvWVm38nVPAAUHioiABSqnAQvMxso6d8knSdpvKQrzWx8LuYCoPBQEQGgUOVqxWuKpLfc/R133yvpKUkX5WguAAoMFREAClWugtcoSe92urwlOdaFmc01szozq2tpaQltcgDyGxURAApVroKXpRjzgwbca9y9wt0rioqKQpgWgFzLtCaCiggAhShXdRJbJH260+XRkt7L0VwA5AlqIgBEXa5WvP4gaayZjTGzwyXNlvTzHM0FQJ6gJgJA1OVkxcvdW83sRkn/I2mgpEfdfW0u5gIgf1ATASDqctZc7+5LJS3N1fMDyD/FxYnNi6nGASAKaK4HkDeoiQAQdQQvAHmDmggAUUfwAhC4TCsiJGoiAERbzvbxAhAPVEQAwAGseAEIFBURAHAAwQtAoKiIAIADCF4AApWuCoKKCABxRPACECgqIgDgAIIXgEOWydGKVEQAwAEc1QjgkPTlaMWqKoIWAEiseAE4RBytCAB9R/ACcEg4WhEA+o7gBeCQcLQiAPQdwQvAIeFoRQDoO4IXgEPC0YoA0HcELwAHyfSk1pzQGgD6hjoJAF1wUmsACA4rXgC6oCYCAIJD8ALQBTURABAcgheALqiJAIDgELwAdEFNBAAEh+AFoAtqIgAgOAQvICYyrYiQqIkAgKBQJwHEABURAJAfWPECYoCKCADIDwQvIAaoiACA/EDwAmKAiggAyA8ELyAGqIgAgPxA8AJigIoIAMgPBC+gwGVaE0FFBADkHnUSQAGjJgIACgsrXkABoyYCAAoLwQsoYNREAEBhIXgBBYyaCAAoLIEFLzP7FzPbYGYNZvacmR2VHC81s4/NrD75tTioOQBRR00EABSWIFe8fiFporuXSXpT0u2drnvb3cuTX/MCnAMQadREAEBhCSx4ufsr7t6avPh7SaODei4giqiJAIDoCWsfr6slvdTp8hgze93MfmVmZ6a7k5nNNbM6M6traWkJfpZAnmiviWhultwP1ESkC18AgMJg7n7odzZbJun4FFctdPfnk7dZKKlC0qXu7mY2WNIwd99uZpMl/T9JE9z9o56eq6Kiwuvq6g55rkAhKS1NhK3uSkoSq1oAgPxmZqvdvaL7eL8KVN39S7086RxJX5U005MJz90/kfRJ8ufVZva2pJMlkaqAJGoiACCagjyq8VxJCyRd6O67O40XmdnA5M8nSRor6Z2g5gEUImoiACCagtzH68eShkv6RbfaiLMkNZjZnyQ9I2meu38Q4DyAgkNNBABEU2DnanT3z6YZf1bSs0E9LxAF7UcmLlyY2LxYXJwIXRyxCACFjeZ6IESZVkRI1EQAQBQFtuIFoKv2ioj2k1q3V0RIhCoAiAtWvICQLFx4IHS12707MQ4AiAeCFxASKiIAAAQvICRURAAACF5ASKiIAAAQvICQVFVJNTWJ0/6YJb7X1LBjPQDECcELyIJMayKoiACAeKNOAugnaiIAAJlixQvoJ2oiAACZIngB/URNBAAgUwQvoJ+oiQAAZIrgBfQTNREAgEwRvIAeZHK0IjURAIBMcVQjkEZfjlasqiJoAQB6x4oXkAZHKwIAso3gBaTB0YoAgGwjeAFpcLQiACDbCF5AGhytCADINoIXkAZHKwIAso3ghdjJ9ITWEie1BgBkF3USiBVOaA0AyCVWvBArVEQAAHKJ4IVYoSICAJBLBC/EChURAIBcInghVqiIAADkEsELsUJFBAAglwheiIxMayKoiAAA5Ap1EogEaiIAAIWAFS9EAjURAIBCQPBCJFATAQAoBAQvRAI1EQCAQkDwQiRQEwEAKAQEL0QCNREAgEIQWPAys0Vm9mczq09+faXTdbeb2Vtm9oaZzQpqDogGaiIAAFERdJ3ED939vs4DZjZe0mxJEySdKGmZmZ3s7m0BzwUFiJoIAECU5GJT40WSnnL3T9x9k6S3JE3JwTxQAKiJAABESdDB60YzazCzR83s6OTYKEnvdrrNluTYQcxsrpnVmVldS0tLwFNFPqImAgAQJf0KXma2zMwaU3xdJOlhSZ+RVC5pq6QftN8txUN5qsd39xp3r3D3iqKiov5MFQWKmggAQJT0ax8vd/9SJrczs59K+u/kxS2SPt3p6tGS3uvPPBBd1dVd9/GSqIkAABSuII9qPKHTxUskNSZ//rmk2WY22MzGSBoraVVQ80BhoyYCABAlQe7jda+ZrTGzBkmVkuZLkruvlfS0pHWSXpZ0A0c0xk+mFRESNREAgOgIrE7C3f++h+uqJbGxKKaoiAAAxBXN9QgdFREAgLgieCF0VEQAAOKK4IXQUREBAIgrghdCV12dqITojIoIAEAcELwQOioiAABxRfBCVmVaE0FFBAAgjgKrk0D8UBMBAEDPWPFC1lATAQBAzwheyBpqIgAA6BnBC1lDTQQAAD0jeCFrqIkAAKBnBC9kDTURAAD0jOCFjFATAQBA/1EngV5REwEAQHaw4oVeURMBAEB2ELzQK2oiAADIDoIXekVNBAAA2UHwQq+oiQAAIDsIXjHWlyMVqYkAAKD/OKoxpvp6pGJVFUELAID+YsUrpjhSEQCA8BG8YoojFQEACB/BK6Y4UhEAgPARvGKKIxUBAAgfwSumOFIRAIDwEbwiiBNaAwCQn6iTiBhOaA0AQP5ixStiqIkAACB/EbwihpoIAADyF8ErYqiJAAAgfxG8IoaaCAAA8hfBK2KoiQAAIH8RvApEphUREjURAADkK+okCgAVEQAARENgK15mtsTM6pNfTWZWnxwvNbOPO123OKg5RAUVEQAARENgK17ufkX7z2b2A0k7Ol39truXB/XcUUNFBAAA0RD4Pl5mZpIul/Rk0M8VVVREAAAQDWHsXH+mpG3uvrHT2Bgze93MfmVmZ6a7o5nNNbM6M6traWkJfqZ5iooIAACioV/By8yWmVljiq+LOt3sSnVd7doqqdjdJ0n6lqT/NLO/SfX47l7j7hXuXlFUVNSfqRY0KiIAAIiGfgUvd/+Su09M8fW8JJnZIEmXSlrS6T6fuPv25M+rJb0t6eT+zKOQZVoTQUUEAACFL+g6iS9J2uDuW9oHzKxI0gfu3mZmJ0kaK+mdgOeRl6iJAAAgXoLex2u2Dt6p/ixJDWb2J0nPSJrn7h8EPI+8RE0EAADxEuiKl7t/I8XYs5KeDfJ5CwU1EQAAxAunDMohaiIAAIgXglcOURMBAEC8ELxyiJoIAADiheAVEGoiAABAd0HXScQSNREAACAVVrwCQE0EAABIheAVAGoiAABAKgSvAFATAQAAUiF4BYCaCAAAkArBKwDURAAAgFQIXn2QaUWERE0EAAA4GHUSGaIiAgAA9BcrXhmiIgIAAPQXwStDVEQAAID+InhliIoIAADQXwSvDFERAQAA+ovglSEqIgAAQH8RvJR5TQQVEQAAoD9iXydBTQQAAAhL7Fe8qIkAAABhiX3woiYCAACEJfbBi5oIAAAQltgHL2oiAABAWGIfvKiJAAAAYYn9UY1SImQRtAAAQNBiv+IFAAAQFoIXAABASAheAAAAISF4AQAAhITgBQAAEBKCFwAAQEgIXgAAACEheAEAAISE4AUAABCSfgUvM7vMzNaa2X4zq+h23e1m9paZvWFmszqNTzazNcnrHjQz688cAAAACkV/V7waJV0qaWXnQTMbL2m2pAmSzpX0kJkNTF79sKS5ksYmv87t5xwAAAAKQr+Cl7uvd/c3Ulx1kaSn3P0Td98k6S1JU8zsBEl/4+6/c3eX9ISki/szBwAAgEIR1EmyR0n6fafLW5Jj+5I/dx9PyczmKrE6Jkm7zCxVyMumYyX9X8DPke/i/hrE/c8v8RpIvAYSr0Hc//wSr4HUv9egJNVgr8HLzJZJOj7FVQvd/fl0d0sx5j2Mp+TuNZJqeptjtphZnbtX9H7L6Ir7axD3P7/EayDxGki8BnH/80u8BlIwr0Gvwcvdv3QIj7tF0qc7XR4t6b3k+OgU4wAAAJEXVJ3EzyXNNrPBZjZGiZ3oV7n7Vkk7zezzyaMZvy4p3aoZAABApPS3TuISM9si6QuSXjSz/5Ekd18r6WlJ6yS9LOkGd29L3u16SY8oscP925Je6s8csiy0zZp5LO6vQdz//BKvgcRrIPEaxP3PL/EaSAG8BpY4uBAAAABBo7keAAAgJAQvAACAkMQyeHGqo67MbImZ1Se/msysPjleamYfd7pucY6nGhgzW2Rmf+70Z/1Kp+tSfiaixsz+xcw2mFmDmT1nZkclx+P0OTg3+T6/ZWbfyfV8wmBmnzazV81sffLvxZuT42l/J6Io+XffmuSftS45doyZ/cLMNia/H53reQbBzD7X6X2uN7OPzOyWqH8GzOxRM3vfzBo7jaV9z7P1b0Es9/Eys1Mk7Zf0E0m3unv7L9l4SU9KmiLpREnLJJ3s7m1mtkrSzUoUwy6V9KC759OBAVlhZj+QtMPdv29mpZL+290n5nhagTOzRZJ2uft93cbTfiZCn2TAzOzLkn7p7q1mdo8kufuCuHwOkqc1e1PSOUpU3/xB0pXuvi6nEwtY8owiJ7j7H81suKTVSpxR5HKl+J2IKjNrklTh7v/XaexeSR+4+93JIH60uy/I1RzDkPw9+LOkMyT9gyL8GTCzsyTtkvRE+99v6d7zbP5bEMsVL051lFpyFe9yJT5cSEj5mcjxnALh7q+4e2vy4u/VtXMvDqZIesvd33H3vZKeUuL9jzR33+ruf0z+vFPSevVwRpGYuUjS48mfH1cE/95PYaakt929OdcTCZq7r5T0QbfhdO951v4tiGXw6sEoSe92utx+SqNR6sOpjgrYmZK2ufvGTmNjzOx1M/uVmZ2Zq4mF5MbkZrZHOy0vp/tMRN3V6lr1EofPQVzf6w7J1c1Jkv43OZTqdyKqXNIrZrbaEqerk6Tjkv2TSn7/VM5mF57Z6vqf7zh9BqT073nW/n6IbPAys2Vm1pjiq6f/wWblVEf5KMPX40p1/YXbKqnY3SdJ+pak/zSzvwlz3tnUy2vwsKTPSCpX4s/9g/a7pXiognrvO8vkc2BmCyW1SqpNDkXqc9CDSL3XfWVmwyQ9K+kWd/9I6X8nomqau58u6TxJNyQ3Q8WKmR0u6UJJ/5UcittnoCdZ+/shqJNk5xynOuqqt9fDzAZJulTS5E73+UTSJ8mfV5vZ25JOllQX4FQDk+lnwsx+Kum/kxfTfSYKUgafgzmSvippZnKzeuQ+Bz2I1HvdF2Z2mBKhq9bdfyZJ7r6t0/Wdfyciyd3fS35/38yeU2Iz0jYzO8HdtyZ3OXk/p5MM3nmS/tj+3sftM5CU7j3P2t8PkV3xOkRxPtXRlyRtcPeOTapmVpTc0VJmdpISr8c7OZpfoJK/YO0ukdR+lEvKz0TY8wuDmZ0raYGkC919d6fxuHwO/iBprJmNSf7Pf7YS73+kJf9O+3dJ6939/k7j6X4nIsfMjkweWCAzO1LSl5X48/5c0pzkzeYoen/vd9dlq0ecPgOdpHvPs/ZvQWRXvHpiZpdI+pGkIiVOdVTv7rPcfa2ZtZ/qqFUHn+roMUlHKLHvS9SOaOy+XV+SzpL0fTNrldQmaZ67d98RMSruNbNyJZaOmyRdJyVOf9XDZyJqfixpsKRfJP4t1u/dfZ5i8jlIHs15o6T/kTRQ0qPJ059F3TRJfy9pjSWrZCTdIenKVL8TEXWcpOeSn/tBkv7T3V82sz9IetrMvilps6TLcjjHQJnZUCWO6O38Pqf8ezEqzOxJSTMkHWuJ0x9+T9LdSvGeZ/PfgljWSQAAAOQCmxoBAABCQvACAAAICcELAAAgJAQvAACAkBC8AAAAQkLwAgAACAnBCwAAICT/H1syrZp+m5dnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions for model_2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ead47ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.19694, 13.070127)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_2 metrics\n",
    "mae_2 = mae(y_test, y_preds_2.squeeze()).numpy()\n",
    "mse_2 = mse(y_test, y_preds_2.squeeze()).numpy()\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bcd5d7",
   "metadata": {},
   "source": [
    "**Build model_3**\n",
    "\n",
    "For our 3rd model, we'll keep everything the same as model_2 except this time we'll train for longer (500 epochs instead of 100).\n",
    "\n",
    "This will give our model more of a chance to learn the patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e2285cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 22.6625 - mae: 22.6625\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.9439 - mae: 16.9439\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8059 - mae: 13.8059\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.4504 - mae: 17.4504\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.0637 - mae: 12.0637\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.8335 - mae: 9.8335\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7023 - mae: 10.7023\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8713 - mae: 10.8713\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 38.0435 - mae: 38.0435\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.6226 - mae: 25.6226\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2375 - mae: 10.2375\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.1960 - mae: 25.1960\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.0177 - mae: 17.0177\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 25.9747 - mae: 25.9747\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.0366 - mae: 18.0366\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.3513 - mae: 7.3513\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8516 - mae: 10.8516\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.5119 - mae: 19.5119\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.3378 - mae: 10.3378\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.6840 - mae: 17.6840\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.8826 - mae: 15.8826\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1778 - mae: 14.1778\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7814 - mae: 8.7814\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0673 - mae: 11.0673\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.6998 - mae: 12.6998\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.2396 - mae: 26.2396\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.7524 - mae: 11.7524\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 22.9252 - mae: 22.9252\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.2439 - mae: 9.2439\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.3121 - mae: 29.3121\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 53.1141 - mae: 53.1141\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.3708 - mae: 12.3708\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1831 - mae: 12.1831\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.9483 - mae: 23.9483\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6223 - mae: 12.6223\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.5243 - mae: 21.5243\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3913 - mae: 11.3913\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4744 - mae: 13.4744\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 10.7992 - mae: 10.7992\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.6026 - mae: 16.6026\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9797 - mae: 10.9797\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3049 - mae: 9.3049\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5985 - mae: 9.5985\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.9750 - mae: 27.9750\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2865 - mae: 11.2865\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.0574 - mae: 14.0574\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.5113 - mae: 13.5113\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.3531 - mae: 17.3531\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5141 - mae: 9.5141\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6965 - mae: 13.6965\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5602 - mae: 11.5602\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.1688 - mae: 30.1688\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.7142 - mae: 13.7142\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 26.3987 - mae: 26.3987\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.9838 - mae: 25.9838\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2307 - mae: 11.2307\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.2025 - mae: 13.2025\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.8624 - mae: 9.8624\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.3870 - mae: 13.3870\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9240 - mae: 10.9240\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.5375 - mae: 13.5375\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.6004 - mae: 17.6004\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1937 - mae: 9.1937\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.4644 - mae: 18.4644\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1481 - mae: 10.1481\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 24.3358 - mae: 24.3358\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9262 - mae: 10.9262\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8005 - mae: 10.8005\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.3092 - mae: 23.3092\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8134 - mae: 8.8134\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.9715 - mae: 15.9715\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.1469 - mae: 8.1469\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.4683 - mae: 9.4683\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.1492 - mae: 28.1492\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2183 - mae: 10.2183\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.1686 - mae: 13.1686\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.4013 - mae: 18.4013\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0304 - mae: 9.0304\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.4406 - mae: 23.4406\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.1121 - mae: 26.1121\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.4009 - mae: 11.4009\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.5022 - mae: 12.5022\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1949 - mae: 17.1949\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.6097 - mae: 6.6097\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.2734 - mae: 20.2734\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.1761 - mae: 10.1761\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.3047 - mae: 24.3047\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.9693 - mae: 18.9693\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1749 - mae: 7.1749\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.2784 - mae: 18.2784\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3343 - mae: 13.3343\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7404 - mae: 8.7404\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.1947 - mae: 14.1947\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.1955 - mae: 17.1955\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.7777 - mae: 16.7777\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1365 - mae: 11.1365\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.1983 - mae: 21.1983\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.4874 - mae: 10.4874\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.5632 - mae: 14.5632\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.7188 - mae: 17.7188\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.2612 - mae: 11.2612\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.9770 - mae: 16.9770\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7652 - mae: 7.7652\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.3546 - mae: 22.3546\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.1002 - mae: 20.1002\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.1066 - mae: 10.1066\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.8571 - mae: 24.8571\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.7659 - mae: 14.7659\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9635 - mae: 8.9635\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2212 - mae: 9.2212\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8236 - mae: 12.8236\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.6232 - mae: 15.6232\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1864 - mae: 11.1864\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.8268 - mae: 24.8268\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.4715 - mae: 13.4715\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3495 - mae: 14.3495\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9492 - mae: 9.9492\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0617 - mae: 11.0617\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1352 - mae: 8.1352\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 30.7020 - mae: 30.7020\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1569 - mae: 8.1569\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.1131 - mae: 29.1131\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.8909 - mae: 33.8909\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.3869 - mae: 20.3869\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.0836 - mae: 9.0836\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2367 - mae: 9.2367\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.2743 - mae: 11.2743\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.0387 - mae: 17.0387\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9837 - mae: 8.9837\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7027 - mae: 23.7027\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7015 - mae: 9.7015\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.9952 - mae: 17.9952\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7527 - mae: 6.7527\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.1872 - mae: 20.1872\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5004 - mae: 10.5004\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.1094 - mae: 18.1094\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.9300 - mae: 22.9300\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0650 - mae: 9.0650\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.8799 - mae: 8.8799\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.2794 - mae: 16.2794\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4378 - mae: 8.4378\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 36.5280 - mae: 36.5280\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.2530 - mae: 25.2530\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.4689 - mae: 10.4689\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.8080 - mae: 25.8080\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.9834 - mae: 9.9834\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7007 - mae: 14.7007\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.8050 - mae: 17.8050\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.4769 - mae: 8.4769\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.6249 - mae: 7.6249\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.9286 - mae: 18.9286\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4785 - mae: 10.4785\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.5113 - mae: 30.5113\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9628 - mae: 9.9628\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7147 - mae: 15.7147\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.5991 - mae: 17.5991\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 31.2961 - mae: 31.2961\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2597 - mae: 10.2597\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 8.7076 - mae: 8.7076\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.8763 - mae: 20.8763\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8638 - mae: 11.8638\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.8613 - mae: 21.8613\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.5261 - mae: 19.5261\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4216 - mae: 11.4216\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.6115 - mae: 11.6115\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.3573 - mae: 21.3573\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.8832 - mae: 26.8832\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0079 - mae: 10.0079\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.1243 - mae: 23.1243\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.5960 - mae: 9.5960\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.8613 - mae: 15.8613\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.8936 - mae: 13.8936\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 22.5890 - mae: 22.5890\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3498 - mae: 11.3498\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 20.0652 - mae: 20.0652\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4087 - mae: 7.4087\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.5979 - mae: 8.5979\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4691 - mae: 15.4691\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.3099 - mae: 9.3099\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1326 - mae: 8.1326\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.6995 - mae: 18.6995\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.7752 - mae: 10.7752\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.9010 - mae: 10.9010\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 33.6795 - mae: 33.6795\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.6256 - mae: 7.6256\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.7550 - mae: 16.7550\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1933 - mae: 10.1933\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.0485 - mae: 23.0485\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.8744 - mae: 9.8744\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.2768 - mae: 15.2768\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.9642 - mae: 9.9642\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.9958 - mae: 14.9958\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 29.6780 - mae: 29.6780\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.3824 - mae: 8.3824\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.9099 - mae: 12.9099\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.9535 - mae: 23.9535\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.7607 - mae: 16.7607\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.4553 - mae: 11.4553\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.5602 - mae: 19.5602\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 15.7255 - mae: 15.7255\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.5874 - mae: 10.5874\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 22.4504 - mae: 22.4504\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 21.6604 - mae: 21.6604\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.2725 - mae: 17.2725\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.4794 - mae: 9.4794\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.1134 - mae: 11.1134\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 17.6007 - mae: 17.6007\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 14.3340 - mae: 14.3340\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.6362 - mae: 16.6362\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.1361 - mae: 18.1361\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9325 - mae: 9.9325\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 18.5932 - mae: 18.5932\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.9831 - mae: 14.9831\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.5550 - mae: 14.5550\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.2258 - mae: 23.2258\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.5046 - mae: 13.5046\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 9.9874 - mae: 9.9874\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.4790 - mae: 12.4790\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.3193 - mae: 5.3193\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.4031 - mae: 12.4031\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.3804 - mae: 22.3804\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.4821 - mae: 21.4821\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.6657 - mae: 11.6657\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.5729 - mae: 13.5729\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.7083 - mae: 15.7083\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.9526 - mae: 14.9526\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.2855 - mae: 15.2855\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.4495 - mae: 17.4495\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 7.2127 - mae: 7.2127\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4579 - mae: 7.4579\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.7665 - mae: 24.7665\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7807 - mae: 8.7807\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.7248 - mae: 24.7248\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.1448 - mae: 8.1448\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7116 - mae: 12.7116\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 7.7151 - mae: 7.7151\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0243 - mae: 10.0243\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5508 - mae: 8.5508\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.8639 - mae: 18.8639\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9871 - mae: 8.9871\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.3864 - mae: 13.3864\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.8832 - mae: 8.8832\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 19.2384 - mae: 19.2384\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.9083 - mae: 13.9083\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.5554 - mae: 14.5554\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 15.6931 - mae: 15.6931\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.5340 - mae: 17.5340\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0999 - mae: 13.0999\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.4328 - mae: 14.4328\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 27.8382 - mae: 27.8382\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.5069 - mae: 7.5069\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 38.1138 - mae: 38.1138\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.9281 - mae: 22.9281\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.4438 - mae: 7.4438\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.8148 - mae: 25.8148\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7325 - mae: 13.7325\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3459 - mae: 8.3459\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 13.2279 - mae: 13.2279\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2463 - mae: 10.2463\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.6563 - mae: 33.6563\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 12.4289 - mae: 12.4289\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.9121 - mae: 8.9121\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.2714 - mae: 8.2714\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.8088 - mae: 18.8088\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.7216 - mae: 11.7216\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.5944 - mae: 13.5944\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.2338 - mae: 11.2338\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.5453 - mae: 19.5453\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 39.5156 - mae: 39.5156\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.1134 - mae: 12.1134\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.3649 - mae: 14.3649\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.7528 - mae: 27.7528\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.2436 - mae: 8.2436\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.4461 - mae: 6.4461\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 34.9599 - mae: 34.9599\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.0558 - mae: 8.0558\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.1170 - mae: 26.1170\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.3321 - mae: 11.3321\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.1102 - mae: 16.1102\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.2435 - mae: 21.2435\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.7810 - mae: 23.7810\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2441 - mae: 8.2441\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 8.4285 - mae: 8.4285\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.6307 - mae: 26.6307\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.2314 - mae: 14.2314\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.2458 - mae: 5.2458\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.8119 - mae: 20.8119\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.6881 - mae: 27.6881\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0046 - mae: 11.0046\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.1976 - mae: 16.1976\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.3652 - mae: 16.3652\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.6295 - mae: 14.6295\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.9419 - mae: 15.9419\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.0848 - mae: 24.0848\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.7127 - mae: 14.7127\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.5065 - mae: 4.5065\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6685 - mae: 9.6685\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.7733 - mae: 23.7733\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.0267 - mae: 19.0267\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8169 - mae: 8.8169\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.8882 - mae: 15.8882\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7412 - mae: 5.7412\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.9852 - mae: 22.9852\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.0575 - mae: 26.0575\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.5871 - mae: 9.5871\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.8152 - mae: 17.8152\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7940 - mae: 9.7940\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 20.5450 - mae: 20.5450\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.6686 - mae: 13.6686\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.6468 - mae: 6.6468\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.3861 - mae: 13.3861\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.1870 - mae: 30.1870\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.2613 - mae: 7.2613\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.5500 - mae: 10.5500\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.5548 - mae: 23.5548\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.4468 - mae: 14.4468\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 20.0024 - mae: 20.0024\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.0088 - mae: 8.0088\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.1317 - mae: 18.1317\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6560 - mae: 10.6560\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0358 - mae: 7.0358\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.6712 - mae: 8.6712\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.3342 - mae: 18.3342\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3114 - mae: 6.3114\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.6203 - mae: 14.6203\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.9930 - mae: 6.9930\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.6297 - mae: 17.6297\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3738 - mae: 14.3738\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.6862 - mae: 17.6862\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.7832 - mae: 6.7832\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 19.7392 - mae: 19.7392\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.5504 - mae: 10.5504\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3365 - mae: 16.3365\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7204 - mae: 9.7204\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.0571 - mae: 13.0571\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.4954 - mae: 32.4954\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.0398 - mae: 11.0398\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.9557 - mae: 19.9557\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 34.3118 - mae: 34.3118\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7204 - mae: 8.7204\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 21.9521 - mae: 21.9521\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.8474 - mae: 13.8474\n",
      "Epoch 343/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6931 - mae: 11.6931\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6911 - mae: 10.6911\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 30.9080 - mae: 30.9080\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6418 - mae: 10.6418\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.5682 - mae: 25.5682\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.2760 - mae: 13.2760\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0389 - mae: 13.0389\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4016 - mae: 15.4016\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.8786 - mae: 32.8786\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 14.0887 - mae: 14.0887\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.7845 - mae: 17.7845\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 11.3456 - mae: 11.3456\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.7768 - mae: 26.7768\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1413 - mae: 10.1413\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.6964 - mae: 14.6964\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.5669 - mae: 14.5669\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.3553 - mae: 12.3553\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 20.3741 - mae: 20.3741\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.8610 - mae: 10.8610\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8143 - mae: 6.8143\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 23.7579 - mae: 23.7579\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.4391 - mae: 29.4391\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.2609 - mae: 8.2609\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1080 - mae: 6.1080\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.5084 - mae: 34.5084\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.3386 - mae: 7.3386\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6853 - mae: 8.6853\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.2204 - mae: 14.2204\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.8365 - mae: 6.8365\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 6.5532 - mae: 6.5532\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.1444 - mae: 24.1444\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.2379 - mae: 10.2379\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8609 - mae: 12.8609\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.7345 - mae: 14.7345\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.6624 - mae: 14.6624\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.1848 - mae: 16.1848\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.6248 - mae: 20.6248\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 34.1467 - mae: 34.1467\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8398 - mae: 8.8398\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5903 - mae: 9.5903\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7475 - mae: 5.7475\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7343 - mae: 8.7343\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9610 - mae: 4.9610\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.1394 - mae: 25.1394\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 15.0848 - mae: 15.0848\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.6537 - mae: 6.6537\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.5735 - mae: 17.5735\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.8722 - mae: 23.8722\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.4860 - mae: 16.4860\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3799 - mae: 8.3799\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.1540 - mae: 18.1540\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.2061 - mae: 14.2061\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.6830 - mae: 28.6830\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.2067 - mae: 8.2067\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4882 - mae: 10.4882\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.3829 - mae: 7.3829\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5525 - mae: 15.5525\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.7261 - mae: 6.7261\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9880 - mae: 7.9880\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3915 - mae: 16.3915\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3790 - mae: 12.3790\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.9715 - mae: 22.9715\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.0145 - mae: 18.0145\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0428 - mae: 7.0428\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.5847 - mae: 12.5847\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6744 - mae: 5.6744\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.0699 - mae: 31.0699\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.2949 - mae: 9.2949\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.9031 - mae: 14.9031\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.8005 - mae: 21.8005\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5131 - mae: 12.5131\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.0941 - mae: 6.0941\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.2518 - mae: 13.2518\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.4879 - mae: 27.4879\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4894 - mae: 10.4894\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8735 - mae: 12.8735\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9124 - mae: 15.9124\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.8210 - mae: 24.8210\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.2070 - mae: 17.2070\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.8224 - mae: 7.8224\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 25.4446 - mae: 25.4446\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.9594 - mae: 14.9594\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1071 - mae: 7.1071\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.1569 - mae: 20.1569\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.2677 - mae: 6.2677\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.6563 - mae: 12.6563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.0960 - mae: 12.0960\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.0939 - mae: 11.0939\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.0177 - mae: 10.0177\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.3635 - mae: 13.3635\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3840 - mae: 11.3840\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.4181 - mae: 30.4181\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.5025 - mae: 10.5025\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.9030 - mae: 28.9030\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6078 - mae: 8.6078\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.7370 - mae: 12.7370\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 33.6905 - mae: 33.6905\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.1092 - mae: 15.1092\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 17.4910 - mae: 17.4910\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 22.3351 - mae: 22.3351\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 23.5135 - mae: 23.5135\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 10.9375 - mae: 10.9375\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9322 - mae: 14.9322\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.0209 - mae: 18.0209\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4084 - mae: 5.4084\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.0721 - mae: 10.0721\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.0213 - mae: 14.0213\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 16.7930 - mae: 16.7930\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 14.2968 - mae: 14.2968\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 30.6382 - mae: 30.6382\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6471 - mae: 7.6471\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 28.1639 - mae: 28.1639\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 7.9552 - mae: 7.9552\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 10.4065 - mae: 10.4065\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.0418 - mae: 15.0418\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 16.5709 - mae: 16.5709\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 26.8802 - mae: 26.8802\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.4289 - mae: 12.4289\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.4970 - mae: 12.4970\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.3265 - mae: 13.3265\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 29.5723 - mae: 29.5723\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4551 - mae: 3.4551\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 15.2294 - mae: 15.2294\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 20.8631 - mae: 20.8631\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 30.4325 - mae: 30.4325\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0177 - mae: 11.0177\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 12.7862 - mae: 12.7862\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3.2208 - mae: 3.2208\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 16.7157 - mae: 16.7157\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.4054 - mae: 13.4054\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 15.2931 - mae: 15.2931\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 11.7604 - mae: 11.7604\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 16.4321 - mae: 16.4321\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 14.0069 - mae: 14.0069\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 30.5862 - mae: 30.5862\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 8.1693 - mae: 8.1693\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.2276 - mae: 11.2276\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 17.8934 - mae: 17.8934\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 15.8000 - mae: 15.8000\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 21.2923 - mae: 21.2923\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 25.4153 - mae: 25.4153\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 24.0084 - mae: 24.0084\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 5.7663 - mae: 5.7663\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 20.0279 - mae: 20.0279\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.0383 - mae: 14.0383\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 30.6057 - mae: 30.6057\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 11.9324 - mae: 11.9324\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 12.7299 - mae: 12.7299\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 23.6069 - mae: 23.6069\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 20.5582 - mae: 20.5582\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 4.9865 - mae: 4.9865\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 12.8094 - mae: 12.8094\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.3707 - mae: 13.3707\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 12.6678 - mae: 12.6678\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 17.6087 - mae: 17.6087\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 23.5822 - mae: 23.5822\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 9.3903 - mae: 9.3903\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6258 - mae: 14.6258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2749c98cfd0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Replicate model_2\n",
    "model_3 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(1),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=['mae'])\n",
    "\n",
    "# Fit the model (this time for 500 epochs, not 100)\n",
    "model_3.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=500) # set verbose t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "311b9f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions for model_3\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions = y_preds_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f933213c",
   "metadata": {},
   "source": [
    "The **Stocatsic Gradient Descent** is not able to find the **Global Minima**, its jumping over the **Global Minima** and is not able to find it. We can decrease the **learning rate** and increase the **epochs** to get better predictions.\n",
    "\n",
    "Or just change the **Optimizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "71838c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68.68784, 4804.469)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_3 metrics\n",
    "mae_3 = mae(y_test, y_preds_3.squeeze()).numpy()\n",
    "mse_3 = mse(y_test, y_preds_3.squeeze()).numpy()\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48dedc",
   "metadata": {},
   "source": [
    "## Comapring Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "149afe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = [[\"model_1\", mae_1, mse_1],\n",
    "                 [\"model_2\", mae_2, mse_2],\n",
    "                 [\"model_3\", mae_3, mae_3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "87354057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>18.745327</td>\n",
       "      <td>353.573364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>3.196940</td>\n",
       "      <td>13.070127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>68.687843</td>\n",
       "      <td>68.687843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        mae         mse\n",
       "0  model_1  18.745327  353.573364\n",
       "1  model_2   3.196940   13.070127\n",
       "2  model_3  68.687843   68.687843"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n",
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ca6244",
   "metadata": {},
   "source": [
    " From our experiments, it looks like model_2 performed the best.\n",
    "\n",
    "And now, you might be thinking, \"wow, comparing models is tedious...\" and it definitely can be, we've only compared 3 models here.\n",
    "\n",
    "But this is part of what machine learning modelling is about, trying many different combinations of models and seeing which performs best.\n",
    "\n",
    "Each model you build is a small experiment.\n",
    "\n",
    "🔑 Note: One of your main goals should be to minimize the time between your experiments. The more experiments you do, the more things you'll figure out which don't work and in turn, get closer to figuring out what does work. Remember the machine learning practitioner's motto: \"experiment, experiment, experiment\".\n",
    "\n",
    "Another thing you'll also find is what you thought may work (such as training a model for longer) may not always work and the exact opposite is also often the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294348d",
   "metadata": {},
   "source": [
    "## Tracking your experiments\n",
    "\n",
    "\n",
    "One really good habit to get into is tracking your modelling experiments to see which perform better than others.\n",
    "\n",
    "We've done a simple version of this above (keeping the results in different variables).\n",
    "\n",
    "📖 Resource: But as you build more models, you'll want to look into using tools such as:\n",
    "\n",
    "* **TensorBoard** - a component of the TensorFlow library to help track modelling experiments (we'll see this later).\n",
    "* **Weights & Biases** - a tool for tracking all kinds of machine learning experiments (the good news for Weights & Biases is it plugs into TensorBoard)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03d0aa",
   "metadata": {},
   "source": [
    "## Saving our models\n",
    "\n",
    "Once you've trained a model and found one which performs to your liking, you'll probably want to save it for use elsewhere (like a web application or mobile device).\n",
    "\n",
    "You can save a TensorFlow/Keras model using model.save().\n",
    "\n",
    "There are two ways to save a model in TensorFlow:\n",
    "\n",
    "1. **The SavedModel format (default)**.\n",
    "2. **The HDF5 format**.\n",
    "\n",
    "\n",
    "The main difference between the two is the SavedModel is automatically able to save custom objects (such as special layers) without additional modifications when loading the model back in.\n",
    "\n",
    "Which one should you use?\n",
    "\n",
    "It depends on your situation but the SavedModel format will suffice most of the time.\n",
    "\n",
    "Both methods use the same method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "25c3b3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_SaveModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save a model using the SaveModel format\n",
    "\n",
    "model_2.save('best_model_SaveModel_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e3b4d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\n",
      "keras_metadata.pb\n",
      "saved_model.pb\n",
      "variables\n"
     ]
    }
   ],
   "source": [
    "# Check it out - outputs a protobuf binary file (.pb) as well as other files\n",
    "!ls best_model_SaveModel_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f760ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model using the HDF5 format\n",
    "\n",
    "model_2.save(\"best_model_HDF5_format.h5\") # note the addition of '.h5' on the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b36f7966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_HDF5_format.h5\n"
     ]
    }
   ],
   "source": [
    "# Check it out\n",
    "!ls best_model_HDF5_format.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d530c9c9",
   "metadata": {},
   "source": [
    "## Loading a Model\n",
    "\n",
    "We can load a saved model using the **load_model()** method\n",
    "\n",
    "Loading a model for the different formats (SavedModel and HDF5) is the same (as long as the pathnames to the particular formats are correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a6ba5494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_saved_model = tf.keras.models.load_model(\"best_model_SaveModel_format\")\n",
    "loaded_saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9f3e36b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with SavedModel format Predictions\n",
    "\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "saved_model_preds = loaded_saved_model.predict(X_test)\n",
    "\n",
    "mae(y_test, saved_model_preds.squeeze()).numpy() == mae(y_test, model_2_preds.squeeze()).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eadbed",
   "metadata": {},
   "source": [
    "Loading model from HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "544ae840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_h5_model = tf.keras.models.load_model(\"best_model_HDF5_format.h5\")\n",
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f3469756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b2b472bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the model_2 prediction with loaded HDF5 predictions\n",
    "h5_model_pred = loaded_h5_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e1ad1963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_model_pred == model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1ff1cd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing the mean squared error\n",
    "mae(y_test, h5_model_pred.squeeze()).numpy() == mae(y_test, h5_model_pred.squeeze()).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8552ca67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70.552185],\n",
       "       [ 75.13991 ],\n",
       "       [ 79.72764 ],\n",
       "       [ 84.315346],\n",
       "       [ 88.90308 ],\n",
       "       [ 93.49081 ],\n",
       "       [ 98.07852 ],\n",
       "       [102.666245],\n",
       "       [107.253975],\n",
       "       [111.84169 ]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e7f6071f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 70.552185,  75.13991 ,  79.72764 ,  84.315346,  88.90308 ,\n",
       "        93.49081 ,  98.07852 , 102.666245, 107.253975, 111.84169 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_model_pred.squeeze()  # reduces the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0d710476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8807b8",
   "metadata": {},
   "source": [
    "## A Large example\n",
    "\n",
    "Alright, we've seen the fundamentals of building neural network regression models in TensorFlow.\n",
    "\n",
    "Let's step it up a notch and build a model for a more feature rich dataset.\n",
    "\n",
    "More specifically we're going to try predict the cost of medical insurance for individuals based on a number of different parameters such as, **age, sex, bmi, children, smoking_status** and **residential_region**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "88194df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Required Libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2f47a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Insurance Dataset\n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "75481320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6da7fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "insurance.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8aabbd",
   "metadata": {},
   "source": [
    "We're going to have to turn the non-numerical columns into numbers (because a neural network can't handle non-numerical inputs).\n",
    "\n",
    "To do so, we'll use the get_dummies() method in pandas.\n",
    "\n",
    "It converts categorical variables (like the sex, smoker and region columns) into numerical variables using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ff2d0bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0   19  27.900         0  16884.92400           1         0          0   \n",
       "1   18  33.770         1   1725.55230           0         1          1   \n",
       "2   28  33.000         3   4449.46200           0         1          1   \n",
       "3   33  22.705         0  21984.47061           0         1          1   \n",
       "4   32  28.880         0   3866.85520           0         1          1   \n",
       "\n",
       "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0           1                 0                 0                 0   \n",
       "1           0                 0                 0                 1   \n",
       "2           0                 0                 0                 1   \n",
       "3           0                 0                 1                 0   \n",
       "4           0                 0                 1                 0   \n",
       "\n",
       "   region_southwest  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn all categories into number\n",
    "insurance_one_hot = pd.get_dummies(insurance) #, drop_first=True)\n",
    "insurance_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6cd06e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y values\n",
    "X = insurance_one_hot.drop(\"charges\", axis=1)\n",
    "y = insurance_one_hot[\"charges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "054bb6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "27081203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42) # set random st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8072523f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 5ms/step - loss: 8868.5918 - mae: 8868.5918\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7887.1606 - mae: 7887.1606\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7537.0942 - mae: 7537.0942\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7859.4346 - mae: 7859.4346\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7639.6699 - mae: 7639.6699\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7578.0850 - mae: 7578.0850\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7514.6177 - mae: 7514.6177\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7694.1343 - mae: 7694.1343\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7595.9141 - mae: 7595.9141\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7735.9126 - mae: 7735.9126\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7444.4194 - mae: 7444.4194\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7678.0332 - mae: 7678.0332\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7681.5850 - mae: 7681.5850\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7702.2866 - mae: 7702.2866\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7585.8950 - mae: 7585.8950\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7689.5396 - mae: 7689.5396\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7509.2061 - mae: 7509.2061\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7695.0103 - mae: 7695.0103\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7669.3755 - mae: 7669.3755\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7901.1372 - mae: 7901.1372\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7552.4844 - mae: 7552.4844\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7844.9980 - mae: 7844.9980\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7642.2515 - mae: 7642.2515\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7515.3101 - mae: 7515.3101\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7678.3530 - mae: 7678.3530\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7653.0293 - mae: 7653.0293\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7559.5474 - mae: 7559.5474\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7459.9419 - mae: 7459.9419\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7618.6201 - mae: 7618.6201\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7628.6255 - mae: 7628.6255\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7540.4922 - mae: 7540.4922\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7486.0186 - mae: 7486.0186\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7418.6636 - mae: 7418.6636\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7480.7334 - mae: 7480.7334\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7615.3125 - mae: 7615.3125\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7566.7925 - mae: 7566.7925\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7661.0903 - mae: 7661.0903\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7522.6846 - mae: 7522.6846\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7556.0703 - mae: 7556.0703\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7433.5688 - mae: 7433.5688\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7722.4346 - mae: 7722.4346\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7344.2710 - mae: 7344.2710\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7597.4341 - mae: 7597.4341\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7338.0137 - mae: 7338.0137\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7510.3472 - mae: 7510.3472\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7413.5815 - mae: 7413.5815\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7451.0391 - mae: 7451.0391\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7340.5396 - mae: 7340.5396\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7481.9990 - mae: 7481.9990\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7468.2852 - mae: 7468.2852\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7411.3413 - mae: 7411.3413\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7460.0801 - mae: 7460.0801\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7601.6611 - mae: 7601.6611\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7241.2549 - mae: 7241.2549\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7539.6968 - mae: 7539.6968\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7293.2012 - mae: 7293.2012\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7417.9727 - mae: 7417.9727\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7353.0615 - mae: 7353.0615\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7643.8252 - mae: 7643.8252\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7410.4004 - mae: 7410.4004\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7612.8345 - mae: 7612.8345\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7387.9092 - mae: 7387.9092\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7359.5615 - mae: 7359.5615\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7109.0889 - mae: 7109.0889\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7396.3228 - mae: 7396.3228\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7179.8618 - mae: 7179.8618\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7289.7729 - mae: 7289.7729\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7523.6987 - mae: 7523.6987\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7442.6172 - mae: 7442.6172\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7673.4849 - mae: 7673.4849\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7276.0332 - mae: 7276.0332\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7246.3726 - mae: 7246.3726\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7372.0728 - mae: 7372.0728\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7512.0762 - mae: 7512.0762\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7269.7446 - mae: 7269.7446\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7199.5059 - mae: 7199.5059\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7261.2935 - mae: 7261.2935\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7185.7646 - mae: 7185.7646\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7301.7500 - mae: 7301.7500\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7002.6313 - mae: 7002.6313\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7289.1367 - mae: 7289.1367\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7155.3960 - mae: 7155.3960\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7475.1719 - mae: 7475.1719\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7387.3687 - mae: 7387.3687\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7289.9468 - mae: 7289.9468\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7268.0957 - mae: 7268.0957\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7238.5889 - mae: 7238.5889\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7201.7363 - mae: 7201.7363\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7538.0771 - mae: 7538.0771\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 6967.1187 - mae: 6967.1187\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7314.1309 - mae: 7314.1309\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7192.3140 - mae: 7192.3140\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7530.8784 - mae: 7530.8784\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7187.3594 - mae: 7187.3594\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7561.5645 - mae: 7561.5645\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7263.4644 - mae: 7263.4644\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7146.2905 - mae: 7146.2905\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7247.9253 - mae: 7247.9253\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7200.6699 - mae: 7200.6699\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7301.6880 - mae: 7301.6880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2749e932880>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a new model (same as model_2)\n",
    "\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model.compile(loss = tf.keras.losses.mae,\n",
    "                       optimizer = tf.keras.optimizers.SGD(),\n",
    "                       metrics = ['mae'])\n",
    "\n",
    "# Fit the model\n",
    "insurance_model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7f5abdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 8628.2520 - mae: 8628.2520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8628.251953125, 8628.251953125]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of Insurance Model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8dcbf730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9575.4421, 13346.089736364489)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comapre the loss with mean and median\n",
    "y_train.median() , y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1bbd4c",
   "metadata": {},
   "source": [
    "Our model didn't perform very well, let's try a bigger model.\n",
    "\n",
    "We'll try 3 things:\n",
    "\n",
    "* Increasing the number of layers (2 -> 3).\n",
    "* Increasing the number of units in each layer (except for the output layer).\n",
    "* Changing the optimizer (from SGD to Adam).\n",
    "\n",
    "Everything else will stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d8544aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13104.4297 - mae: 13104.4297\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12749.5410 - mae: 12749.5410\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 985us/step - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 10905.8164 - mae: 10905.8164\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9457.7227 - mae: 9457.7227\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8147.6543 - mae: 8147.6543\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7528.8413 - mae: 7528.8413\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7409.0815 - mae: 7409.0815\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7368.9180 - mae: 7368.9180\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7348.5195 - mae: 7348.5195\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7307.5815 - mae: 7307.5815\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7265.7104 - mae: 7265.7104\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7242.5488 - mae: 7242.5488\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7197.1978 - mae: 7197.1978\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7101.9199 - mae: 7101.9199\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7052.3296 - mae: 7052.3296\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7024.3511 - mae: 7024.3511\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6969.0122 - mae: 6969.0122\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6911.7280 - mae: 6911.7280\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6789.6855 - mae: 6789.6855\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6720.2026 - mae: 6720.2026\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6689.7158 - mae: 6689.7158\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6652.4614 - mae: 6652.4614\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6618.1016 - mae: 6618.1016\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6585.8633 - mae: 6585.8633\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6559.4956 - mae: 6559.4956\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6530.0435 - mae: 6530.0435\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6475.9263 - mae: 6475.9263\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6458.8984 - mae: 6458.8984\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6417.7510 - mae: 6417.7510\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6403.2759 - mae: 6403.2759\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6378.7451 - mae: 6378.7451\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6364.9126 - mae: 6364.9126\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6351.5269 - mae: 6351.5269\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6337.6606 - mae: 6337.6606\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6324.8364 - mae: 6324.8364\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6310.1948 - mae: 6310.1948\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6284.8696 - mae: 6284.8696\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6253.0103 - mae: 6253.0103\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6218.0430 - mae: 6218.0430\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6183.9590 - mae: 6183.9590\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6171.2993 - mae: 6171.2993\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6148.8403 - mae: 6148.8403\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6132.5981 - mae: 6132.5981\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6092.7202 - mae: 6092.7202\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6059.4873 - mae: 6059.4873\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6031.3848 - mae: 6031.3848\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5995.2168 - mae: 5995.2168\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5963.0718 - mae: 5963.0718\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5940.0610 - mae: 5940.0610\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5887.9990 - mae: 5887.9990\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5861.6987 - mae: 5861.6987\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 5834.3066 - mae: 5834.3066\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5772.3232 - mae: 5772.3232\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5745.1514 - mae: 5745.1514\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5711.3477 - mae: 5711.3477\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5674.5215 - mae: 5674.5215\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5639.4927 - mae: 5639.4927\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5600.6650 - mae: 5600.6650\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5559.4326 - mae: 5559.4326\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5523.6191 - mae: 5523.6191\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5474.1250 - mae: 5474.1250\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5386.0522 - mae: 5386.0522\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5288.8159 - mae: 5288.8159\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5234.6792 - mae: 5234.6792\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5170.9360 - mae: 5170.9360\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5112.9443 - mae: 5112.9443\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5060.0854 - mae: 5060.0854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x191206bb8b0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a new model (same as model_2)\n",
    "\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100) , #activation=\"relu\"),  # 100 units\n",
    "    tf.keras.layers.Dense(10),                      # 10 units\n",
    "    tf.keras.layers.Dense(1)                        # 1 units (important for output)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model.compile(loss = tf.keras.losses.mae,\n",
    "                       optimizer = tf.keras.optimizers.Adam(),  # SGD doesn't work\n",
    "                       metrics = ['mae'])\n",
    "\n",
    "# Fit the model\n",
    "insurance_model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "06c85ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 8628.2520 - mae: 8628.2520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8628.251953125, 8628.251953125]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of Insurance Model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "958ca79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 3ms/step - loss: 12255.0576 - mae: 12255.0576\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7624.7441 - mae: 7624.7441\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7308.0225 - mae: 7308.0225\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7133.7031 - mae: 7133.7031\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6938.4385 - mae: 6938.4385\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6718.6958 - mae: 6718.6958\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 6508.7764 - mae: 6508.7764\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 6362.2778 - mae: 6362.2778\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6248.7173 - mae: 6248.7173\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6098.0464 - mae: 6098.0464\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 5920.4932 - mae: 5920.4932\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5715.0718 - mae: 5715.0718\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5478.1006 - mae: 5478.1006\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5069.6196 - mae: 5069.6196\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 4536.6450 - mae: 4536.6450\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3920.7603 - mae: 3920.7603\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3654.4712 - mae: 3654.4712\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3512.6785 - mae: 3512.6785\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3513.0127 - mae: 3513.0127\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3426.9922 - mae: 3426.9922\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3456.5444 - mae: 3456.5444\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3350.0884 - mae: 3350.0884\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3343.8679 - mae: 3343.8679\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3281.1577 - mae: 3281.1577\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3265.8022 - mae: 3265.8022\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3246.1655 - mae: 3246.1655\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3165.9790 - mae: 3165.9790\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3056.8958 - mae: 3056.8958\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2983.0056 - mae: 2983.0056\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2913.1331 - mae: 2913.1331\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2903.2109 - mae: 2903.2109\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2908.4102 - mae: 2908.4102\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2857.4670 - mae: 2857.4670\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2922.0496 - mae: 2922.0496\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2811.1736 - mae: 2811.1736\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2798.0977 - mae: 2798.0977\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2747.8137 - mae: 2747.8137\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2735.1702 - mae: 2735.1702\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2731.7136 - mae: 2731.7136\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2733.0583 - mae: 2733.0583\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2722.3926 - mae: 2722.3926\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2750.4102 - mae: 2750.4102\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2702.2905 - mae: 2702.2905\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2640.8984 - mae: 2640.8984\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2664.6099 - mae: 2664.6099\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2619.5469 - mae: 2619.5469\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2644.9182 - mae: 2644.9182\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2612.5415 - mae: 2612.5415\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2558.5662 - mae: 2558.5662\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2573.5913 - mae: 2573.5913\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2584.5979 - mae: 2584.5979\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2533.3560 - mae: 2533.3560\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2518.6553 - mae: 2518.6553\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2527.8289 - mae: 2527.8289\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2551.6636 - mae: 2551.6636\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2548.8887 - mae: 2548.8887\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2460.9531 - mae: 2460.9531\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2463.7493 - mae: 2463.7493\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2446.3359 - mae: 2446.3359\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2449.8384 - mae: 2449.8384\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2497.0312 - mae: 2497.0312\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2415.6914 - mae: 2415.6914\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2403.9333 - mae: 2403.9333\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2432.8340 - mae: 2432.8340\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2365.6082 - mae: 2365.6082\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2409.9292 - mae: 2409.9292\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2344.7070 - mae: 2344.7070\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2337.2163 - mae: 2337.2163\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2331.7715 - mae: 2331.7715\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2312.6846 - mae: 2312.6846\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2323.3628 - mae: 2323.3628\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2307.6045 - mae: 2307.6045\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2312.2512 - mae: 2312.2512\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2274.7551 - mae: 2274.7551\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2256.7358 - mae: 2256.7358\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2258.6143 - mae: 2258.6143\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2249.8245 - mae: 2249.8245\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2261.3105 - mae: 2261.3105\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2248.3521 - mae: 2248.3521\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2220.4167 - mae: 2220.4167\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2272.0093 - mae: 2272.0093\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2295.9268 - mae: 2295.9268\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2236.4915 - mae: 2236.4915\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2194.9917 - mae: 2194.9917\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2182.8577 - mae: 2182.8577\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2226.3818 - mae: 2226.3818\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2232.1091 - mae: 2232.1091\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2160.0227 - mae: 2160.0227\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2148.5154 - mae: 2148.5154\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2219.6711 - mae: 2219.6711\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2167.4307 - mae: 2167.4307\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2187.0830 - mae: 2187.0830\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2185.9717 - mae: 2185.9717\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2159.5845 - mae: 2159.5845\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2206.3574 - mae: 2206.3574\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2125.1216 - mae: 2125.1216\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2159.6711 - mae: 2159.6711\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2150.5793 - mae: 2150.5793\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2125.1338 - mae: 2125.1338\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2127.3669 - mae: 2127.3669\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a new model (same as model_2)\n",
    "\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),  # 100 units\n",
    "    tf.keras.layers.Dense(10),                      # 10 units\n",
    "    tf.keras.layers.Dense(1)                        # 1 units (important for output)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model.compile(loss = tf.keras.losses.mae,\n",
    "                       optimizer = tf.keras.optimizers.Adam(0.01),  # SGD doesn't work\n",
    "                       metrics = ['mae'])\n",
    "\n",
    "# Fit the model\n",
    "history = insurance_model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "19890261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 1962.6758 - mae: 1962.6758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1962.67578125, 1962.67578125]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of Insurance Model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d523d5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history (also known as a loss curve)\n",
    "\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "662d7dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [12255.0576171875,\n",
       "  7624.744140625,\n",
       "  7308.0224609375,\n",
       "  7133.703125,\n",
       "  6938.4384765625,\n",
       "  6718.69580078125,\n",
       "  6508.7763671875,\n",
       "  6362.27783203125,\n",
       "  6248.71728515625,\n",
       "  6098.04638671875,\n",
       "  5920.4931640625,\n",
       "  5715.07177734375,\n",
       "  5478.1005859375,\n",
       "  5069.61962890625,\n",
       "  4536.64501953125,\n",
       "  3920.76025390625,\n",
       "  3654.47119140625,\n",
       "  3512.678466796875,\n",
       "  3513.0126953125,\n",
       "  3426.9921875,\n",
       "  3456.54443359375,\n",
       "  3350.08837890625,\n",
       "  3343.867919921875,\n",
       "  3281.15771484375,\n",
       "  3265.80224609375,\n",
       "  3246.16552734375,\n",
       "  3165.97900390625,\n",
       "  3056.895751953125,\n",
       "  2983.005615234375,\n",
       "  2913.133056640625,\n",
       "  2903.2109375,\n",
       "  2908.41015625,\n",
       "  2857.467041015625,\n",
       "  2922.049560546875,\n",
       "  2811.173583984375,\n",
       "  2798.09765625,\n",
       "  2747.813720703125,\n",
       "  2735.170166015625,\n",
       "  2731.713623046875,\n",
       "  2733.058349609375,\n",
       "  2722.392578125,\n",
       "  2750.41015625,\n",
       "  2702.29052734375,\n",
       "  2640.8984375,\n",
       "  2664.60986328125,\n",
       "  2619.546875,\n",
       "  2644.918212890625,\n",
       "  2612.54150390625,\n",
       "  2558.566162109375,\n",
       "  2573.59130859375,\n",
       "  2584.597900390625,\n",
       "  2533.35595703125,\n",
       "  2518.6552734375,\n",
       "  2527.828857421875,\n",
       "  2551.66357421875,\n",
       "  2548.888671875,\n",
       "  2460.953125,\n",
       "  2463.749267578125,\n",
       "  2446.3359375,\n",
       "  2449.83837890625,\n",
       "  2497.03125,\n",
       "  2415.69140625,\n",
       "  2403.933349609375,\n",
       "  2432.833984375,\n",
       "  2365.608154296875,\n",
       "  2409.92919921875,\n",
       "  2344.70703125,\n",
       "  2337.21630859375,\n",
       "  2331.771484375,\n",
       "  2312.6845703125,\n",
       "  2323.36279296875,\n",
       "  2307.6044921875,\n",
       "  2312.251220703125,\n",
       "  2274.755126953125,\n",
       "  2256.73583984375,\n",
       "  2258.6142578125,\n",
       "  2249.824462890625,\n",
       "  2261.310546875,\n",
       "  2248.35205078125,\n",
       "  2220.416748046875,\n",
       "  2272.00927734375,\n",
       "  2295.9267578125,\n",
       "  2236.491455078125,\n",
       "  2194.99169921875,\n",
       "  2182.857666015625,\n",
       "  2226.3818359375,\n",
       "  2232.109130859375,\n",
       "  2160.022705078125,\n",
       "  2148.515380859375,\n",
       "  2219.671142578125,\n",
       "  2167.4306640625,\n",
       "  2187.0830078125,\n",
       "  2185.9716796875,\n",
       "  2159.58447265625,\n",
       "  2206.357421875,\n",
       "  2125.12158203125,\n",
       "  2159.671142578125,\n",
       "  2150.579345703125,\n",
       "  2125.1337890625,\n",
       "  2127.366943359375],\n",
       " 'mae': [12255.0576171875,\n",
       "  7624.744140625,\n",
       "  7308.0224609375,\n",
       "  7133.703125,\n",
       "  6938.4384765625,\n",
       "  6718.69580078125,\n",
       "  6508.7763671875,\n",
       "  6362.27783203125,\n",
       "  6248.71728515625,\n",
       "  6098.04638671875,\n",
       "  5920.4931640625,\n",
       "  5715.07177734375,\n",
       "  5478.1005859375,\n",
       "  5069.61962890625,\n",
       "  4536.64501953125,\n",
       "  3920.76025390625,\n",
       "  3654.47119140625,\n",
       "  3512.678466796875,\n",
       "  3513.0126953125,\n",
       "  3426.9921875,\n",
       "  3456.54443359375,\n",
       "  3350.08837890625,\n",
       "  3343.867919921875,\n",
       "  3281.15771484375,\n",
       "  3265.80224609375,\n",
       "  3246.16552734375,\n",
       "  3165.97900390625,\n",
       "  3056.895751953125,\n",
       "  2983.005615234375,\n",
       "  2913.133056640625,\n",
       "  2903.2109375,\n",
       "  2908.41015625,\n",
       "  2857.467041015625,\n",
       "  2922.049560546875,\n",
       "  2811.173583984375,\n",
       "  2798.09765625,\n",
       "  2747.813720703125,\n",
       "  2735.170166015625,\n",
       "  2731.713623046875,\n",
       "  2733.058349609375,\n",
       "  2722.392578125,\n",
       "  2750.41015625,\n",
       "  2702.29052734375,\n",
       "  2640.8984375,\n",
       "  2664.60986328125,\n",
       "  2619.546875,\n",
       "  2644.918212890625,\n",
       "  2612.54150390625,\n",
       "  2558.566162109375,\n",
       "  2573.59130859375,\n",
       "  2584.597900390625,\n",
       "  2533.35595703125,\n",
       "  2518.6552734375,\n",
       "  2527.828857421875,\n",
       "  2551.66357421875,\n",
       "  2548.888671875,\n",
       "  2460.953125,\n",
       "  2463.749267578125,\n",
       "  2446.3359375,\n",
       "  2449.83837890625,\n",
       "  2497.03125,\n",
       "  2415.69140625,\n",
       "  2403.933349609375,\n",
       "  2432.833984375,\n",
       "  2365.608154296875,\n",
       "  2409.92919921875,\n",
       "  2344.70703125,\n",
       "  2337.21630859375,\n",
       "  2331.771484375,\n",
       "  2312.6845703125,\n",
       "  2323.36279296875,\n",
       "  2307.6044921875,\n",
       "  2312.251220703125,\n",
       "  2274.755126953125,\n",
       "  2256.73583984375,\n",
       "  2258.6142578125,\n",
       "  2249.824462890625,\n",
       "  2261.310546875,\n",
       "  2248.35205078125,\n",
       "  2220.416748046875,\n",
       "  2272.00927734375,\n",
       "  2295.9267578125,\n",
       "  2236.491455078125,\n",
       "  2194.99169921875,\n",
       "  2182.857666015625,\n",
       "  2226.3818359375,\n",
       "  2232.109130859375,\n",
       "  2160.022705078125,\n",
       "  2148.515380859375,\n",
       "  2219.671142578125,\n",
       "  2167.4306640625,\n",
       "  2187.0830078125,\n",
       "  2185.9716796875,\n",
       "  2159.58447265625,\n",
       "  2206.357421875,\n",
       "  2125.12158203125,\n",
       "  2159.671142578125,\n",
       "  2150.579345703125,\n",
       "  2125.1337890625,\n",
       "  2127.366943359375]}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e929da1",
   "metadata": {},
   "source": [
    "From this, it looks like our model's loss (and MAE) were both still decreasing (in our case, MAE and loss are the same, hence the lines in the plot overlap eachother).\n",
    "\n",
    "What this tells us is the loss might go down if we try training it for longer.\n",
    "\n",
    "\n",
    "🤔 **Question: How long should you train for?**\n",
    "\n",
    "It depends on what problem you're working on. Sometimes training won't take very long, other times it'll take longer than you expect. A common method is to set your model training for a very long time (e.g. 1000's of epochs) but set it up with an EarlyStopping callback so it stops automatically when it stops improving. We'll see this in another module.\n",
    "\n",
    "Let's train the same model as above for a little longer. We can do this but calling fit on it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "33e0bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12255.0576 - mae: 12255.0576\n",
      "Epoch 2/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7624.7441 - mae: 7624.7441\n",
      "Epoch 3/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7308.0225 - mae: 7308.0225\n",
      "Epoch 4/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7133.7031 - mae: 7133.7031\n",
      "Epoch 5/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6938.4385 - mae: 6938.4385\n",
      "Epoch 6/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6718.6958 - mae: 6718.6958\n",
      "Epoch 7/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6508.7764 - mae: 6508.7764\n",
      "Epoch 8/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6362.2778 - mae: 6362.2778\n",
      "Epoch 9/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6248.7173 - mae: 6248.7173\n",
      "Epoch 10/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6098.0464 - mae: 6098.0464\n",
      "Epoch 11/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5920.4932 - mae: 5920.4932\n",
      "Epoch 12/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5715.0718 - mae: 5715.0718\n",
      "Epoch 13/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5478.1006 - mae: 5478.1006\n",
      "Epoch 14/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5069.6196 - mae: 5069.6196\n",
      "Epoch 15/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4536.6450 - mae: 4536.6450\n",
      "Epoch 16/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3920.7603 - mae: 3920.7603\n",
      "Epoch 17/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3654.4712 - mae: 3654.4712\n",
      "Epoch 18/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3512.6785 - mae: 3512.6785\n",
      "Epoch 19/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3513.0127 - mae: 3513.0127\n",
      "Epoch 20/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3426.9922 - mae: 3426.9922\n",
      "Epoch 21/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3456.5444 - mae: 3456.5444\n",
      "Epoch 22/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3350.0884 - mae: 3350.0884\n",
      "Epoch 23/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3343.8679 - mae: 3343.8679\n",
      "Epoch 24/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3281.1577 - mae: 3281.1577\n",
      "Epoch 25/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3265.8022 - mae: 3265.8022\n",
      "Epoch 26/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3246.1655 - mae: 3246.1655\n",
      "Epoch 27/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3165.9790 - mae: 3165.9790\n",
      "Epoch 28/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3056.8958 - mae: 3056.8958\n",
      "Epoch 29/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2983.0056 - mae: 2983.0056\n",
      "Epoch 30/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2913.1331 - mae: 2913.1331\n",
      "Epoch 31/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2903.2109 - mae: 2903.2109\n",
      "Epoch 32/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2908.4102 - mae: 2908.4102\n",
      "Epoch 33/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2857.4670 - mae: 2857.4670\n",
      "Epoch 34/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2922.0496 - mae: 2922.0496\n",
      "Epoch 35/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2811.1736 - mae: 2811.1736\n",
      "Epoch 36/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2798.0977 - mae: 2798.0977\n",
      "Epoch 37/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2747.8137 - mae: 2747.8137\n",
      "Epoch 38/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2735.1702 - mae: 2735.1702\n",
      "Epoch 39/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2731.7136 - mae: 2731.7136\n",
      "Epoch 40/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2733.0583 - mae: 2733.0583\n",
      "Epoch 41/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2722.3926 - mae: 2722.3926\n",
      "Epoch 42/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2750.4102 - mae: 2750.4102\n",
      "Epoch 43/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2702.2905 - mae: 2702.2905\n",
      "Epoch 44/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2640.8984 - mae: 2640.8984\n",
      "Epoch 45/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2664.6099 - mae: 2664.6099\n",
      "Epoch 46/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2619.5469 - mae: 2619.5469\n",
      "Epoch 47/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2644.9182 - mae: 2644.9182\n",
      "Epoch 48/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2612.5415 - mae: 2612.5415\n",
      "Epoch 49/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2558.5662 - mae: 2558.5662\n",
      "Epoch 50/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2573.5913 - mae: 2573.5913\n",
      "Epoch 51/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2584.5979 - mae: 2584.5979\n",
      "Epoch 52/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2533.3560 - mae: 2533.3560\n",
      "Epoch 53/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2518.6553 - mae: 2518.6553\n",
      "Epoch 54/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2527.8289 - mae: 2527.8289\n",
      "Epoch 55/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2551.6636 - mae: 2551.6636\n",
      "Epoch 56/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2548.8887 - mae: 2548.8887\n",
      "Epoch 57/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2460.9531 - mae: 2460.9531\n",
      "Epoch 58/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2463.7493 - mae: 2463.7493\n",
      "Epoch 59/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2446.3359 - mae: 2446.3359\n",
      "Epoch 60/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2449.8384 - mae: 2449.8384\n",
      "Epoch 61/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2497.0312 - mae: 2497.0312\n",
      "Epoch 62/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2415.6914 - mae: 2415.6914\n",
      "Epoch 63/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2403.9333 - mae: 2403.9333\n",
      "Epoch 64/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2432.8340 - mae: 2432.8340\n",
      "Epoch 65/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2365.6082 - mae: 2365.6082\n",
      "Epoch 66/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2409.9292 - mae: 2409.9292\n",
      "Epoch 67/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2344.7070 - mae: 2344.7070\n",
      "Epoch 68/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2337.2163 - mae: 2337.2163\n",
      "Epoch 69/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2331.7715 - mae: 2331.7715\n",
      "Epoch 70/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2312.6846 - mae: 2312.6846\n",
      "Epoch 71/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2323.3628 - mae: 2323.3628\n",
      "Epoch 72/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2307.6045 - mae: 2307.6045\n",
      "Epoch 73/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2312.2512 - mae: 2312.2512\n",
      "Epoch 74/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2274.7551 - mae: 2274.7551\n",
      "Epoch 75/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2256.7358 - mae: 2256.7358\n",
      "Epoch 76/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2258.6143 - mae: 2258.6143\n",
      "Epoch 77/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2249.8245 - mae: 2249.8245\n",
      "Epoch 78/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2261.3105 - mae: 2261.3105\n",
      "Epoch 79/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2248.3521 - mae: 2248.3521\n",
      "Epoch 80/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2220.4167 - mae: 2220.4167\n",
      "Epoch 81/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2272.0093 - mae: 2272.0093\n",
      "Epoch 82/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2295.9268 - mae: 2295.9268\n",
      "Epoch 83/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2236.4915 - mae: 2236.4915\n",
      "Epoch 84/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2194.9917 - mae: 2194.9917\n",
      "Epoch 85/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2182.8577 - mae: 2182.8577\n",
      "Epoch 86/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2226.3818 - mae: 2226.3818\n",
      "Epoch 87/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2232.1091 - mae: 2232.1091\n",
      "Epoch 88/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2160.0227 - mae: 2160.0227\n",
      "Epoch 89/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2148.5154 - mae: 2148.5154\n",
      "Epoch 90/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2219.6711 - mae: 2219.6711\n",
      "Epoch 91/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2167.4307 - mae: 2167.4307\n",
      "Epoch 92/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2187.0830 - mae: 2187.0830\n",
      "Epoch 93/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2185.9717 - mae: 2185.9717\n",
      "Epoch 94/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2159.5845 - mae: 2159.5845\n",
      "Epoch 95/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2206.3574 - mae: 2206.3574\n",
      "Epoch 96/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2125.1216 - mae: 2125.1216\n",
      "Epoch 97/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2159.6711 - mae: 2159.6711\n",
      "Epoch 98/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2150.5793 - mae: 2150.5793\n",
      "Epoch 99/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2125.1338 - mae: 2125.1338\n",
      "Epoch 100/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2127.3669 - mae: 2127.3669\n",
      "Epoch 101/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2134.1338 - mae: 2134.1338\n",
      "Epoch 102/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2156.0659 - mae: 2156.0659\n",
      "Epoch 103/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2078.3167 - mae: 2078.3167\n",
      "Epoch 104/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2095.0273 - mae: 2095.0273\n",
      "Epoch 105/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2150.4673 - mae: 2150.4673\n",
      "Epoch 106/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2153.8188 - mae: 2153.8188\n",
      "Epoch 107/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2105.1726 - mae: 2105.1726\n",
      "Epoch 108/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2109.7073 - mae: 2109.7073\n",
      "Epoch 109/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2156.5515 - mae: 2156.5515\n",
      "Epoch 110/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2084.7310 - mae: 2084.7310\n",
      "Epoch 111/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2105.1716 - mae: 2105.1716\n",
      "Epoch 112/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2096.7639 - mae: 2096.7639\n",
      "Epoch 113/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2101.0547 - mae: 2101.0547\n",
      "Epoch 114/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2174.8123 - mae: 2174.8123\n",
      "Epoch 115/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2112.7014 - mae: 2112.7014\n",
      "Epoch 116/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2106.4641 - mae: 2106.4641\n",
      "Epoch 117/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2132.4990 - mae: 2132.4990\n",
      "Epoch 118/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2094.5732 - mae: 2094.5732\n",
      "Epoch 119/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2145.7498 - mae: 2145.7498\n",
      "Epoch 120/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2146.4478 - mae: 2146.4478\n",
      "Epoch 121/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2149.9375 - mae: 2149.9375\n",
      "Epoch 122/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2074.9050 - mae: 2074.9050\n",
      "Epoch 123/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2080.9141 - mae: 2080.9141\n",
      "Epoch 124/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2074.8125 - mae: 2074.8125\n",
      "Epoch 125/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2081.3999 - mae: 2081.3999\n",
      "Epoch 126/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2114.8186 - mae: 2114.8186\n",
      "Epoch 127/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2104.8052 - mae: 2104.8052\n",
      "Epoch 128/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2070.9849 - mae: 2070.9849\n",
      "Epoch 129/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2081.4297 - mae: 2081.4297\n",
      "Epoch 130/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2159.7844 - mae: 2159.7844\n",
      "Epoch 131/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2093.6465 - mae: 2093.6465\n",
      "Epoch 132/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2041.1904 - mae: 2041.1904\n",
      "Epoch 133/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2095.7568 - mae: 2095.7568\n",
      "Epoch 134/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2085.7532 - mae: 2085.7532\n",
      "Epoch 135/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2063.8867 - mae: 2063.8867\n",
      "Epoch 136/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2078.4189 - mae: 2078.4189\n",
      "Epoch 137/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2074.1028 - mae: 2074.1028\n",
      "Epoch 138/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2061.8242 - mae: 2061.8242\n",
      "Epoch 139/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2062.0125 - mae: 2062.0125\n",
      "Epoch 140/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2064.6118 - mae: 2064.6118\n",
      "Epoch 141/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2088.5920 - mae: 2088.5920\n",
      "Epoch 142/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2142.5422 - mae: 2142.5422\n",
      "Epoch 143/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2106.9365 - mae: 2106.9365\n",
      "Epoch 144/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2137.2104 - mae: 2137.2104\n",
      "Epoch 145/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2118.3948 - mae: 2118.3948\n",
      "Epoch 146/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2113.3347 - mae: 2113.3347\n",
      "Epoch 147/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2089.3037 - mae: 2089.3037\n",
      "Epoch 148/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2096.0120 - mae: 2096.0120\n",
      "Epoch 149/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2062.4302 - mae: 2062.4302\n",
      "Epoch 150/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2063.1267 - mae: 2063.1267\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a new model (same as model_2)\n",
    "\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),  # 100 units\n",
    "    tf.keras.layers.Dense(10),                      # 10 units\n",
    "    tf.keras.layers.Dense(1)                        # 1 units (important for output)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model.compile(loss = tf.keras.losses.mae,\n",
    "                       optimizer = tf.keras.optimizers.Adam(0.01),  # SGD doesn't work\n",
    "                       metrics = ['mae'])\n",
    "\n",
    "# Fit the model\n",
    "history = insurance_model.fit(X_train, y_train, epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "050c01c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step - loss: 1962.6758 - mae: 1962.6758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1962.67578125, 1962.67578125]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of Insurance Model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "10a86c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history (also known as a loss curve)\n",
    "\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4ac3e5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 1s 3ms/step - loss: 12255.0576 - mae: 12255.0576\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7624.7441 - mae: 7624.7441\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7308.0225 - mae: 7308.0225\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7133.7031 - mae: 7133.7031\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6938.4385 - mae: 6938.4385\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6718.6958 - mae: 6718.6958\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6508.7764 - mae: 6508.7764\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6362.2778 - mae: 6362.2778\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6248.7173 - mae: 6248.7173\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6098.0464 - mae: 6098.0464\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 5920.4932 - mae: 5920.4932\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 5715.0718 - mae: 5715.0718\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5478.1006 - mae: 5478.1006\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5069.6196 - mae: 5069.6196\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4536.6450 - mae: 4536.6450\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3920.7603 - mae: 3920.7603\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3654.4712 - mae: 3654.4712\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3512.6785 - mae: 3512.6785\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3513.0127 - mae: 3513.0127\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3426.9922 - mae: 3426.9922\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3456.5444 - mae: 3456.5444\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3350.0884 - mae: 3350.0884\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3343.8679 - mae: 3343.8679\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3281.1577 - mae: 3281.1577\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3265.8022 - mae: 3265.8022\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3246.1655 - mae: 3246.1655\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3165.9790 - mae: 3165.9790\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3056.8958 - mae: 3056.8958\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2983.0056 - mae: 2983.0056\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2913.1331 - mae: 2913.1331\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2903.2109 - mae: 2903.2109\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2908.4102 - mae: 2908.4102\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2857.4670 - mae: 2857.4670\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2922.0496 - mae: 2922.0496\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2811.1736 - mae: 2811.1736\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2798.0977 - mae: 2798.0977\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2747.8137 - mae: 2747.8137\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2735.1702 - mae: 2735.1702\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2731.7136 - mae: 2731.7136\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2733.0583 - mae: 2733.0583\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2722.3926 - mae: 2722.3926\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2750.4102 - mae: 2750.4102\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2702.2905 - mae: 2702.2905\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2640.8984 - mae: 2640.8984\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2664.6099 - mae: 2664.6099\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2619.5469 - mae: 2619.5469\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2644.9182 - mae: 2644.9182\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2612.5415 - mae: 2612.5415\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2558.5662 - mae: 2558.5662\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2573.5913 - mae: 2573.5913\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2584.5979 - mae: 2584.5979\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2533.3560 - mae: 2533.3560\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2518.6553 - mae: 2518.6553\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2527.8289 - mae: 2527.8289\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2551.6636 - mae: 2551.6636\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2548.8887 - mae: 2548.8887\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2460.9531 - mae: 2460.9531\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2463.7493 - mae: 2463.7493\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2446.3359 - mae: 2446.3359\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2449.8384 - mae: 2449.8384\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2497.0312 - mae: 2497.0312\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2415.6914 - mae: 2415.6914\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2403.9333 - mae: 2403.9333\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2432.8340 - mae: 2432.8340\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2365.6082 - mae: 2365.6082\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2409.9292 - mae: 2409.9292\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2344.7070 - mae: 2344.7070\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2337.2163 - mae: 2337.2163\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2331.7715 - mae: 2331.7715\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2312.6846 - mae: 2312.6846\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2323.3628 - mae: 2323.3628\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2307.6045 - mae: 2307.6045\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2312.2512 - mae: 2312.2512\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2274.7551 - mae: 2274.7551\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2256.7358 - mae: 2256.7358\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2258.6143 - mae: 2258.6143\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2249.8245 - mae: 2249.8245\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2261.3105 - mae: 2261.3105\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2248.3521 - mae: 2248.3521\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2220.4167 - mae: 2220.4167\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2272.0093 - mae: 2272.0093\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2295.9268 - mae: 2295.9268\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2236.4915 - mae: 2236.4915\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2194.9917 - mae: 2194.9917\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2182.8577 - mae: 2182.8577\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2226.3818 - mae: 2226.3818\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2232.1091 - mae: 2232.1091\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2160.0227 - mae: 2160.0227\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2148.5154 - mae: 2148.5154\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2219.6711 - mae: 2219.6711\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2167.4307 - mae: 2167.4307\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2187.0830 - mae: 2187.0830\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2185.9717 - mae: 2185.9717\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2159.5845 - mae: 2159.5845\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2206.3574 - mae: 2206.3574\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2125.1216 - mae: 2125.1216\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2159.6711 - mae: 2159.6711\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2150.5793 - mae: 2150.5793\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2125.1338 - mae: 2125.1338\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2127.3669 - mae: 2127.3669\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2134.1338 - mae: 2134.1338\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2156.0659 - mae: 2156.0659\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2078.3167 - mae: 2078.3167\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2095.0273 - mae: 2095.0273\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2150.4673 - mae: 2150.4673\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2153.8188 - mae: 2153.8188\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2105.1726 - mae: 2105.1726\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2109.7073 - mae: 2109.7073\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2156.5515 - mae: 2156.5515\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2084.7310 - mae: 2084.7310\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2105.1716 - mae: 2105.1716\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2096.7639 - mae: 2096.7639\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2101.0547 - mae: 2101.0547\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2174.8123 - mae: 2174.8123\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2112.7014 - mae: 2112.7014\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2106.4641 - mae: 2106.4641\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2132.4990 - mae: 2132.4990\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2094.5732 - mae: 2094.5732\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2145.7498 - mae: 2145.7498\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2146.4478 - mae: 2146.4478\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2149.9375 - mae: 2149.9375\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2074.9050 - mae: 2074.9050\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2080.9141 - mae: 2080.9141\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2074.8125 - mae: 2074.8125\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2081.3999 - mae: 2081.3999\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2114.8186 - mae: 2114.8186\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2104.8052 - mae: 2104.8052\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2070.9849 - mae: 2070.9849\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2081.4297 - mae: 2081.4297\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2159.7844 - mae: 2159.7844\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2093.6465 - mae: 2093.6465\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2041.1904 - mae: 2041.1904\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2095.7568 - mae: 2095.7568\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2085.7532 - mae: 2085.7532\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2063.8867 - mae: 2063.8867\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2078.4189 - mae: 2078.4189\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2074.1028 - mae: 2074.1028\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2061.8242 - mae: 2061.8242\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2062.0125 - mae: 2062.0125\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2064.6118 - mae: 2064.6118\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2088.5920 - mae: 2088.5920\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2142.5422 - mae: 2142.5422\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2106.9365 - mae: 2106.9365\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2137.2104 - mae: 2137.2104\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2118.3948 - mae: 2118.3948\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2113.3347 - mae: 2113.3347\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2089.3037 - mae: 2089.3037\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2096.0120 - mae: 2096.0120\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2062.4302 - mae: 2062.4302\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2063.1267 - mae: 2063.1267\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2087.6169 - mae: 2087.6169\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2117.8550 - mae: 2117.8550\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2098.2622 - mae: 2098.2622\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2075.5930 - mae: 2075.5930\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2044.3556 - mae: 2044.3556\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2051.3335 - mae: 2051.3335\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2043.9694 - mae: 2043.9694\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2073.7266 - mae: 2073.7266\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2177.9197 - mae: 2177.9197\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2080.5562 - mae: 2080.5562\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2055.4331 - mae: 2055.4331\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 6ms/step - loss: 2080.3418 - mae: 2080.3418\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2052.1223 - mae: 2052.1223\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2066.4998 - mae: 2066.4998\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2066.2229 - mae: 2066.2229\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2058.9678 - mae: 2058.9678\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 2061.3132 - mae: 2061.3132\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 2070.8777 - mae: 2070.8777\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 2021.8701 - mae: 2021.8701\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2015.4698 - mae: 2015.4698\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2091.6833 - mae: 2091.6833\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2012.7180 - mae: 2012.7180\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2079.0745 - mae: 2079.0745\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2049.9705 - mae: 2049.9705\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2067.4600 - mae: 2067.4600\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2039.5355 - mae: 2039.5355\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2058.6467 - mae: 2058.6467\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2044.7416 - mae: 2044.7416\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2051.7908 - mae: 2051.7908\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2054.8667 - mae: 2054.8667\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2051.5186 - mae: 2051.5186\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2011.8425 - mae: 2011.8425\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2094.3821 - mae: 2094.3821\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2108.3057 - mae: 2108.3057\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 2095.7761 - mae: 2095.7761\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2069.5537 - mae: 2069.5537\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2040.3119 - mae: 2040.3119\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2067.9526 - mae: 2067.9526\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2084.8184 - mae: 2084.8184\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2024.2264 - mae: 2024.2264\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2020.7935 - mae: 2020.7935\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2061.1113 - mae: 2061.1113\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2056.5403 - mae: 2056.5403\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2010.3687 - mae: 2010.3687\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2092.2441 - mae: 2092.2441\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2024.6533 - mae: 2024.6533\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2079.5742 - mae: 2079.5742\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2041.1292 - mae: 2041.1292\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2152.2102 - mae: 2152.2102\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2102.2053 - mae: 2102.2053\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a new model (same as model_2)\n",
    "\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),  # 100 units\n",
    "    tf.keras.layers.Dense(10),                      # 10 units\n",
    "    tf.keras.layers.Dense(1)                        # 1 units (important for output)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model.compile(loss = tf.keras.losses.mae,\n",
    "                       optimizer = tf.keras.optimizers.Adam(0.01),  # SGD doesn't work\n",
    "                       metrics = ['mae'])\n",
    "\n",
    "# Fit the model\n",
    "history = insurance_model.fit(X_train, y_train, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e1b7bcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 1792.7042 - mae: 1792.7042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1792.7042236328125, 1792.7042236328125]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of Insurance Model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3224fc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history (also known as a loss curve)\n",
    "\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c9b2e0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 1792.7042 - mae: 1792.7042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1792.7042236328125, 1792.7042236328125)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model_2_loss, insurance_model_2_mae = insurance_model.evaluate(X_test, y_test)\n",
    "insurance_model_2_loss, insurance_model_2_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f942faa",
   "metadata": {},
   "source": [
    "## Callbacks, Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7af25857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12255.0576 - mae: 12255.0576\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7624.7441 - mae: 7624.7441\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7308.0225 - mae: 7308.0225\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7133.7031 - mae: 7133.7031\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6938.4385 - mae: 6938.4385\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6718.6958 - mae: 6718.6958\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6508.7764 - mae: 6508.7764\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6362.2778 - mae: 6362.2778\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6248.7173 - mae: 6248.7173\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6098.0464 - mae: 6098.0464\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5920.4932 - mae: 5920.4932\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5715.0718 - mae: 5715.0718\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5478.1006 - mae: 5478.1006\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5069.6196 - mae: 5069.6196\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4536.6450 - mae: 4536.6450\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3920.7603 - mae: 3920.7603\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3654.4712 - mae: 3654.4712\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3512.6785 - mae: 3512.6785\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3513.0127 - mae: 3513.0127\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3426.9922 - mae: 3426.9922\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3456.5444 - mae: 3456.5444\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3350.0884 - mae: 3350.0884\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3343.8679 - mae: 3343.8679\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3281.1577 - mae: 3281.1577\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3265.8022 - mae: 3265.8022\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3246.1655 - mae: 3246.1655\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3165.9790 - mae: 3165.9790\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3056.8958 - mae: 3056.8958\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2983.0056 - mae: 2983.0056\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2913.1331 - mae: 2913.1331\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2903.2109 - mae: 2903.2109\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2908.4102 - mae: 2908.4102\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2857.4670 - mae: 2857.4670\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2922.0496 - mae: 2922.0496\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2811.1736 - mae: 2811.1736\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2798.0977 - mae: 2798.0977\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2747.8137 - mae: 2747.8137\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2735.1702 - mae: 2735.1702\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2731.7136 - mae: 2731.7136\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2733.0583 - mae: 2733.0583\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2722.3926 - mae: 2722.3926\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2750.4102 - mae: 2750.4102\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2702.2905 - mae: 2702.2905\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2640.8984 - mae: 2640.8984\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2664.6099 - mae: 2664.6099\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2619.5469 - mae: 2619.5469\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2644.9182 - mae: 2644.9182\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2612.5415 - mae: 2612.5415\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2558.5662 - mae: 2558.5662\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2573.5913 - mae: 2573.5913\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2584.5979 - mae: 2584.5979\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2533.3560 - mae: 2533.3560\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2518.6553 - mae: 2518.6553\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2527.8289 - mae: 2527.8289\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2551.6636 - mae: 2551.6636\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2548.8887 - mae: 2548.8887\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2460.9531 - mae: 2460.9531\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2463.7493 - mae: 2463.7493\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2446.3359 - mae: 2446.3359\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2449.8384 - mae: 2449.8384\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2497.0312 - mae: 2497.0312\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2415.6914 - mae: 2415.6914\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2403.9333 - mae: 2403.9333\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2432.8340 - mae: 2432.8340\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2365.6082 - mae: 2365.6082\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2409.9292 - mae: 2409.9292\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2344.7070 - mae: 2344.7070\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2337.2163 - mae: 2337.2163\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2331.7715 - mae: 2331.7715\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2312.6846 - mae: 2312.6846\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2323.3628 - mae: 2323.3628\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2307.6045 - mae: 2307.6045\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2312.2512 - mae: 2312.2512\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2274.7551 - mae: 2274.7551\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2256.7358 - mae: 2256.7358\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2258.6143 - mae: 2258.6143\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2249.8245 - mae: 2249.8245\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2261.3105 - mae: 2261.3105\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2248.3521 - mae: 2248.3521\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2220.4167 - mae: 2220.4167\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2272.0093 - mae: 2272.0093\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2295.9268 - mae: 2295.9268\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2236.4915 - mae: 2236.4915\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2194.9917 - mae: 2194.9917\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2182.8577 - mae: 2182.8577\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2226.3818 - mae: 2226.3818\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2232.1091 - mae: 2232.1091\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2160.0227 - mae: 2160.0227\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2148.5154 - mae: 2148.5154\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2219.6711 - mae: 2219.6711\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2167.4307 - mae: 2167.4307\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2187.0830 - mae: 2187.0830\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2185.9717 - mae: 2185.9717\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2159.5845 - mae: 2159.5845\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a new model (same as model_2)\n",
    "\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),  # 100 units\n",
    "    tf.keras.layers.Dense(10),                      # 10 units\n",
    "    tf.keras.layers.Dense(1)                        # 1 units (important for output)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model.compile(loss = tf.keras.losses.mae,\n",
    "                       optimizer = tf.keras.optimizers.Adam(0.01),  # SGD doesn't work\n",
    "                       metrics = ['mae'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "history = insurance_model.fit(X_train, y_train, epochs = 200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c4d60b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 1792.7042 - mae: 1792.7042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1792.7042236328125, 1792.7042236328125]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bf23cebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history (also known as a loss curve)\n",
    "\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fdfd3d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 1792.7042 - mae: 1792.7042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1792.7042236328125, 1792.7042236328125)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model_2_loss, insurance_model_2_mae = insurance_model.evaluate(X_test, y_test)\n",
    "insurance_model_2_loss, insurance_model_2_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f46f3",
   "metadata": {},
   "source": [
    "## Preprocessing Data (normalization and standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "49612988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0      19  27.900         0           1         0          0           1   \n",
       "1      18  33.770         1           0         1          1           0   \n",
       "2      28  33.000         3           0         1          1           0   \n",
       "3      33  22.705         0           0         1          1           0   \n",
       "4      32  28.880         0           0         1          1           0   \n",
       "...   ...     ...       ...         ...       ...        ...         ...   \n",
       "1333   50  30.970         3           0         1          1           0   \n",
       "1334   18  31.920         0           1         0          1           0   \n",
       "1335   18  36.850         0           1         0          1           0   \n",
       "1336   21  25.800         0           1         0          1           0   \n",
       "1337   61  29.070         0           1         0          0           1   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                    0                 0                 0                 1  \n",
       "1                    0                 0                 1                 0  \n",
       "2                    0                 0                 1                 0  \n",
       "3                    0                 1                 0                 0  \n",
       "4                    0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "1333                 0                 1                 0                 0  \n",
       "1334                 1                 0                 0                 0  \n",
       "1335                 0                 0                 1                 0  \n",
       "1336                 0                 0                 0                 1  \n",
       "1337                 0                 1                 0                 0  \n",
       "\n",
       "[1338 rows x 11 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a951a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Insurance Dataset\n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "700f7966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "27e56fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5b0f7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Column Tranformer\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # turns all values between 0 and 1\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
    ")\n",
    "\n",
    "X = insurance.drop(\"charges\", axis=1)\n",
    "y = insurance['charges']\n",
    "\n",
    "# Create training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42) # set random st\n",
    "\n",
    "\n",
    "# Fit the column transformer to our training data\n",
    "ct.fit(X_train)\n",
    "\n",
    "\n",
    "# Transform training  and test data with normalization (MinMaxSCaler) and OneHotEncoder\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5ee0ccca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60869565, 0.10734463, 0.4       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.63043478, 0.22491256, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.73913043, 0.23944041, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "630ec97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 1s 3ms/step - loss: 13269.0762 - mae: 13269.0762\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 12005.4141 - mae: 12005.4141\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8644.8701 - mae: 8644.8701\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7708.6387 - mae: 7708.6387\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7299.9780 - mae: 7299.9780\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6826.0718 - mae: 6826.0718\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6138.2314 - mae: 6138.2314\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 5170.1060 - mae: 5170.1060\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4159.4829 - mae: 4159.4829\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3687.2188 - mae: 3687.2188\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3594.2185 - mae: 3594.2185\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3501.5720 - mae: 3501.5720\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3421.0845 - mae: 3421.0845\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3373.0850 - mae: 3373.0850\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3316.3850 - mae: 3316.3850\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3279.1753 - mae: 3279.1753\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3270.6206 - mae: 3270.6206\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3246.0339 - mae: 3246.0339\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3219.2803 - mae: 3219.2803\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3219.4561 - mae: 3219.4561\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3210.3723 - mae: 3210.3723\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3211.5820 - mae: 3211.5820\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3216.2017 - mae: 3216.2017\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3207.8076 - mae: 3207.8076\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3218.2878 - mae: 3218.2878\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3204.9473 - mae: 3204.9473\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3206.2888 - mae: 3206.2888\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3199.1013 - mae: 3199.1013\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3223.4226 - mae: 3223.4226\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3185.3008 - mae: 3185.3008\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3191.0920 - mae: 3191.0920\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3182.7002 - mae: 3182.7002\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3185.8975 - mae: 3185.8975\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3180.5420 - mae: 3180.5420\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3172.9575 - mae: 3172.9575\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3167.8213 - mae: 3167.8213\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3164.8252 - mae: 3164.8252\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3162.1611 - mae: 3162.1611\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3159.9375 - mae: 3159.9375\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3160.6460 - mae: 3160.6460\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3145.0625 - mae: 3145.0625\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3146.9089 - mae: 3146.9089\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3140.6021 - mae: 3140.6021\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3136.7417 - mae: 3136.7417\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3143.7324 - mae: 3143.7324\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3131.4895 - mae: 3131.4895\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3119.1270 - mae: 3119.1270\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3120.5178 - mae: 3120.5178\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3107.4631 - mae: 3107.4631\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3098.0193 - mae: 3098.0193\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3083.8271 - mae: 3083.8271\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3076.5596 - mae: 3076.5596\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3066.4675 - mae: 3066.4675\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3073.1865 - mae: 3073.1865\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3073.7849 - mae: 3073.7849\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3044.3057 - mae: 3044.3057\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3038.3010 - mae: 3038.3010\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3036.3032 - mae: 3036.3032\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3021.0483 - mae: 3021.0483\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3001.9944 - mae: 3001.9944\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3001.9709 - mae: 3001.9709\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2986.6953 - mae: 2986.6953\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2983.8955 - mae: 2983.8955\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2959.1392 - mae: 2959.1392\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2941.9329 - mae: 2941.9329\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2945.2654 - mae: 2945.2654\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2925.5002 - mae: 2925.5002\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2906.6167 - mae: 2906.6167\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2900.1045 - mae: 2900.1045\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2891.6313 - mae: 2891.6313\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2874.0735 - mae: 2874.0735\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2857.8711 - mae: 2857.8711\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2841.9241 - mae: 2841.9241\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2821.0176 - mae: 2821.0176\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2817.0027 - mae: 2817.0027\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2798.6167 - mae: 2798.6167\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2782.5862 - mae: 2782.5862\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2770.3433 - mae: 2770.3433\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2757.5886 - mae: 2757.5886\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2734.4243 - mae: 2734.4243\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2729.6272 - mae: 2729.6272\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2712.8652 - mae: 2712.8652\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2683.4211 - mae: 2683.4211\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2661.8496 - mae: 2661.8496\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2663.9902 - mae: 2663.9902\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2624.7412 - mae: 2624.7412\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2606.8372 - mae: 2606.8372\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2590.7673 - mae: 2590.7673\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2569.6963 - mae: 2569.6963\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2554.2327 - mae: 2554.2327\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2535.2527 - mae: 2535.2527\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2517.2834 - mae: 2517.2834\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2498.9702 - mae: 2498.9702\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2485.2830 - mae: 2485.2830\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2461.3435 - mae: 2461.3435\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2445.6104 - mae: 2445.6104\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2443.8933 - mae: 2443.8933\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2404.1018 - mae: 2404.1018\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2392.5454 - mae: 2392.5454\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2371.0137 - mae: 2371.0137\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2363.5723 - mae: 2363.5723\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2355.6072 - mae: 2355.6072\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2343.8125 - mae: 2343.8125\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2321.8650 - mae: 2321.8650\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2310.7698 - mae: 2310.7698\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2302.2573 - mae: 2302.2573\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2292.0051 - mae: 2292.0051\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2277.8315 - mae: 2277.8315\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2274.1455 - mae: 2274.1455\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2271.3816 - mae: 2271.3816\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2246.2527 - mae: 2246.2527\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2245.1213 - mae: 2245.1213\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2231.5071 - mae: 2231.5071\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2225.0830 - mae: 2225.0830\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2218.6177 - mae: 2218.6177\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2200.1929 - mae: 2200.1929\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2195.1812 - mae: 2195.1812\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2186.2722 - mae: 2186.2722\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2173.2856 - mae: 2173.2856\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2175.9827 - mae: 2175.9827\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2159.8647 - mae: 2159.8647\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2149.6404 - mae: 2149.6404\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2142.2559 - mae: 2142.2559\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2132.3823 - mae: 2132.3823\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2126.8584 - mae: 2126.8584\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2123.3516 - mae: 2123.3516\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2113.5366 - mae: 2113.5366\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2101.5566 - mae: 2101.5566\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2092.7439 - mae: 2092.7439\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2098.7344 - mae: 2098.7344\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2084.3757 - mae: 2084.3757\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2082.2166 - mae: 2082.2166\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2079.2610 - mae: 2079.2610\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2078.0562 - mae: 2078.0562\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2066.1323 - mae: 2066.1323\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2052.6680 - mae: 2052.6680\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2053.1504 - mae: 2053.1504\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2051.0439 - mae: 2051.0439\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2044.4573 - mae: 2044.4573\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2043.7958 - mae: 2043.7958\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2056.9287 - mae: 2056.9287\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2036.0281 - mae: 2036.0281\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2034.7065 - mae: 2034.7065\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2023.8929 - mae: 2023.8929\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2020.2605 - mae: 2020.2605\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2011.5780 - mae: 2011.5780\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2014.1490 - mae: 2014.1490\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2013.4044 - mae: 2013.4044\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2010.5273 - mae: 2010.5273\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2012.3809 - mae: 2012.3809\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2005.1124 - mae: 2005.1124\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2005.2799 - mae: 2005.2799\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2008.9465 - mae: 2008.9465\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2018.5437 - mae: 2018.5437\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2009.1565 - mae: 2009.1565\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2008.1617 - mae: 2008.1617\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1999.5491 - mae: 1999.5491\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1999.7758 - mae: 1999.7758\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2006.8911 - mae: 2006.8911\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2011.8014 - mae: 2011.8014\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1996.2341 - mae: 1996.2341\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 5ms/step - loss: 1992.8566 - mae: 1992.8566\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1991.2303 - mae: 1991.2303\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1996.9760 - mae: 1996.9760\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2000.7638 - mae: 2000.7638\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1988.8538 - mae: 1988.8538\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1995.8566 - mae: 1995.8566\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 2010.4659 - mae: 2010.4659\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1996.4203 - mae: 1996.4203\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1992.0399 - mae: 1992.0399\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1991.8888 - mae: 1991.8888\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 1998.9246 - mae: 1998.9246\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2009.0173 - mae: 2009.0173\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 2011.7513 - mae: 2011.7513\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2015.1467 - mae: 2015.1467\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1991.2065 - mae: 1991.2065\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1993.1523 - mae: 1993.1523\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2003.8218 - mae: 2003.8218\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1987.6641 - mae: 1987.6641\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1986.3320 - mae: 1986.3320\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1993.1395 - mae: 1993.1395\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1989.0514 - mae: 1989.0514\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 1987.2815 - mae: 1987.2815\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 2006.1846 - mae: 2006.1846\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 1982.5447 - mae: 1982.5447\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1994.4468 - mae: 1994.4468\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1986.4149 - mae: 1986.4149\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2003.7958 - mae: 2003.7958\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1981.2812 - mae: 1981.2812\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1983.7518 - mae: 1983.7518\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 1980.4591 - mae: 1980.4591\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1989.5365 - mae: 1989.5365\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 2002.7867 - mae: 2002.7867\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1977.5626 - mae: 1977.5626\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1978.7191 - mae: 1978.7191\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1982.5616 - mae: 1982.5616\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 1983.7748 - mae: 1983.7748\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1983.3032 - mae: 1983.3032\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1986.1462 - mae: 1986.1462\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1977.4149 - mae: 1977.4149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x274a13dc820>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Neural Network Model to fit on our Normalized Data\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the Model\n",
    "\n",
    "insurance_model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "])\n",
    "\n",
    "# 2. Compile the Model\n",
    "insurance_model_4.compile(loss = tf.keras.losses.mae,\n",
    "                         optimizer = tf.keras.optimizers.Adam(0.01),\n",
    "                         metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the Model\n",
    "insurance_model_4.fit(X_train_normal, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "75cd7e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step - loss: 1737.9021 - mae: 1737.9021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1737.902099609375, 1737.902099609375]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our insurance model trained on Normalised Data\n",
    "\n",
    "insurance_model_4.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b154a598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_55 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,221\n",
      "Trainable params: 2,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "insurance_model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd8f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
